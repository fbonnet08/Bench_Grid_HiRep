

        #for i in range(len(target_file_cluster_lst[:])):
        # Getting the mpi_distribution, lattice size and number of nodes
        #ith_file = os.path.basename(target_file_cluster_lst[i].split('\n')[0]).split('.out')[0].split('Run_')[1].split(batch_act+'_')[1].split('_'+sim_size)[0]
        #print(len(nnodes_lst[:]))
        #for k in range(len(nnodes_lst[:])):
        #    lattice_sz_lst.append(str(lattice_sz_value))
        # [end-for-loop [j]]

                #print(split_string)

                #print(lattice_sz_value)

    #print(" printing the dictionary ---->: ", bench_BKeeper_dict)


from mpl_toolkits.mplot3d import Axes3D
x_label = "mpi_distribution"
y_label = "CG Run Time (s)"
z_label = "FlOp/S (GFlOp/s)"
# Sample data
#mpi_distribution = df_su2_adj_leonardo_mpi_node002[x_label]  # Example MPI configurations
#flops            = numpy.array(df_su2_adj_leonardo_cgtimes_node002[y_label])  # Example performance values (GFlop/s)
#cg_runtime       = numpy.array(df_su2_adj_leonardo_flops_node002[z_label])  # Example CG Run Time (s)
'''
# Create a 3D figure
fig = matplotlib.pyplot.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
ax.scatter(mpi_distribution, flops, cg_runtime, c='r', marker='o')

# Labels
ax.set_xlabel(x_label)
ax.set_ylabel(y_label)
ax.set_zlabel(z_label)

matplotlib.pyplot.title("3D Performance Visualization")
matplotlib.pyplot.show()
'''


# Data from the table
mpi_distribution = df_su2_adj_leonardo_mpi_node002[x_label] #["01-01-01-04", "01-01-01-04", "01-01-01-04", "01-01-02-02", "01-01-02-02", "01-01-02-02", "01-01-02-04", "01-01-02-04","01-01-02-04", "01-02-01-04"]
cg_run_time      = df_su2_adj_leonardo_cgtimes_node002[y_label] #[0.106523, 0.058752, 0.072020, 0.075592, 0.051122, 0.105030, 0.070195, 0.061927, 0.093687, 0.091574]
flop_s           = df_su2_adj_leonardo_flops_node002[z_label] #[1895.86642, 1720.13929, 2804.12911, 2671.62369, 1976.87148, 1922.81613, 1439.72682, 3261.15230, 2155.61794, 2205.35718]
# Convert mpi_distribution to numerical values
unique_mpi = list(set(mpi_distribution))
mpi_numeric = [unique_mpi.index(mpi) for mpi in mpi_distribution]

# Create 3D plot
fig = matplotlib.pyplot.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
sc = ax.scatter(cg_run_time, flop_s, mpi_numeric, c=mpi_numeric, cmap='viridis', marker='o')

# Labels and titles
ax.set_xlabel("CG Run Time (s)")
ax.set_ylabel("FlOp/S (GFlOp/s)")
ax.set_zlabel("MPI Distribution (Encoded)")
ax.set_title("3D Scatter Plot of Lattice QCD Runs")

# Custom legend for MPI distribution
from matplotlib.lines import Line2D
legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='C'+str(i), markersize=10, label=mpi) for i, mpi in enumerate(unique_mpi)]
ax.legend(handles=legend_elements, title="MPI Distribution")

matplotlib.pyplot.show()

'''


# Convert mpi_distribution to numerical values
unique_mpi = list(set(mpi_distribution))
mpi_numeric = [unique_mpi.index(mpi) for mpi in mpi_distribution]

# Create mesh grid for 3D surface plot
X, Y = numpy.meshgrid(numpy.linspace(min(mpi_numeric), max(mpi_numeric), 10),
                   numpy.linspace(min(flop_s), max(flop_s), 10))
Z = numpy.interp(X, mpi_numeric, cg_run_time)  # Interpolating Z values

# Create 3D plot
fig = matplotlib.pyplot.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
sc = ax.scatter(mpi_numeric, flop_s, cg_run_time, c=cg_run_time, cmap='viridis', marker='o')

# 3D Mesh surface
ax.plot_surface(X, Y, Z, alpha=0.5, cmap='coolwarm', edgecolor='k')

# Labels and titles
ax.set_xlabel("MPI Distribution (Encoded)")
ax.set_ylabel("FlOp/S (GFlOp/s)")
ax.set_zlabel("CG Run Time (s)")
ax.set_title("3D Scatter Plot with Mesh of Lattice QCD Runs")

# Custom legend for MPI distribution
from matplotlib.lines import Line2D
legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='C'+str(i), markersize=10, label=mpi) for i, mpi in enumerate(unique_mpi)]
ax.legend(handles=legend_elements, title="MPI Distribution")

matplotlib.pyplot.show()

'''













print(batch_act)
print(sim_size)



        #for ikey in range(len(start_key_rep_lst[:])):
        #    start_key_rep_ith = start_key_rep_lst[ikey]
        #    print(" start_key_rep_ith -->: ", start_key_rep_ith)
        #    if start_key_rep_ith in  line.split('\n')[0]:
        #        rep_value = str(start_key_rep_ith).split('Performing benchmark for ')[1]
        #        representation_lst.append(rep_value)
        #rep_value = "empty_string"


            rep_value = str(line.split('\n')[0]).split('Performing benchmark for ')[1].split(' #')[0]
            #print("rep_value --->: ", rep_value)

  cg_run_time_lst, FlOps_GFlOps_lst, Comms_MB_lst, Memory_GB_lst, mpi_distribution_lst, nnodes_lst, lattice_size_lst, representation_lst

print("target_file_cluster_lst[i] -->: ", target_file_cluster_lst[i])

    #start_bkeeper_key = "BKeeper"
    # Starting the parsing of files over the start_key_lst
    # TODO: loop over the representation key
    #ikey = 0

    end_key_rep = "###############################################"

    print(" printing the dictionary ---->: ", bench_BKeeper_dict)

    exit(c.get_RC_FAIL())
    print ("representation_lst[:]      --->: ", representation_lst[:] )
    print ("len(representation_lst[:]) --->: ", len(representation_lst[:]) )
    print ("cg_run_time_lst[:]         --->: ", cg_run_time_lst[:] )
    print ("len(cg_run_time_lst[:])    --->: ", len(cg_run_time_lst[:]) )
    print ("run_file_name_lst[:]       --->: ", run_file_name_lst[:] )
    print ("len(run_file_name_lst[:])    --->: ", len(run_file_name_lst[:]) )



# ----------------------------------------------------------------------------
machine_name_lumi = "Lumi"
DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_lumi,'LatticeRuns')
# ----------------------------------------------------------------------------

print(target_file_lst_lumi[:])


        msg = ""
        if batch_action == "BKeeper_run_gpu":
        elif "Sombrero" in batch_action:
            msg = (os.path.join(c.getData_path(), batch_action.replace('_cpu',''), simulation_size, str(target_file_lst[i].split(".sh")[0]), target_file_lst[i])).strip()
         [end-if]


print(target_Sombrero_weak_small_file_lst_lumi[:])
print(target_Sombrero_weak_small_file_cluster_lst_lumi[:])


dataframe_representation_lst_vega = [df_su2_adj_vega, df_su2_fun_vega, df_su3_fun_vega]

rc = plot_representation_matplotlib(c, m, dataframe_representation_lst_vega, machine_name_vega)



dataframe_representation_lst_leonardo = [df_su2_adj_leonardo, df_su2_fun_leonardo, df_su3_fun_leonardo]

rc = plot_representation_matplotlib(c, m, dataframe_representation_lst_leonardo, machine_name_leonardo)

#df_su2_adj_lumi_mpi_node002 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "002"][["mpi_distribution"]]


df_su2_adj_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi["Representation"] == "SU(2), adjoint"][["Representation", "CG Run Time (s)","mpi_distribution","nodes"]]
df_su2_fun_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi["Representation"] == "SU(2), fundamental"][["Representation", "CG Run Time (s)","mpi_distribution","nodes"]]
df_su3_fun_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi["Representation"] == "SU(3), fundamental"][["Representation", "CG Run Time (s)","mpi_distribution","nodes"]]

# PLotting data

df_su2_adj_lumi_mpi_node001     = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["mpi_distribution"]]
df_su2_adj_lumi_cgtimes_node001 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su2_fun_lumi_cgtimes_node001 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su3_fun_lumi_cgtimes_node001 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]

rc = plot_BenchRes_groupByBars_matplotlib(c, m,
                                          df_su2_adj_lumi_mpi_node001['mpi_distribution'],
                                          df_su2_adj_lumi_cgtimes_node001['CG Run Time (s)'],
                                          df_su2_fun_lumi_cgtimes_node001['CG Run Time (s)'],
                                          df_su3_fun_lumi_cgtimes_node001['CG Run Time (s)'],
                                          machine_name_lumi, "node001")


#df_su2_adj_lumi_mpi_node002 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "002"][["mpi_distribution"]]

df_su2_adj_lumi_mpi_node002     = df_su2_adj_lumi[df_su2_adj_lumi["nodes"] == "002"][["mpi_distribution"]]
df_su2_adj_lumi_cgtimes_node002 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)"]]
df_su2_fun_lumi_cgtimes_node002 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)"]]
df_su3_fun_lumi_cgtimes_node002 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)"]]


rc = plot_BenchRes_groupByBars_matplotlib(c, m,
                                          df_su2_adj_lumi_mpi_node002['mpi_distribution'],
                                          df_su2_adj_lumi_cgtimes_node002['CG Run Time (s)'],
                                          df_su2_fun_lumi_cgtimes_node002['CG Run Time (s)'],
                                          df_su3_fun_lumi_cgtimes_node002['CG Run Time (s)'],
                                          machine_name_lumi, "node002")



df_su2_adj_lumi_mpi_node001     = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["mpi_distribution"]]
df_su2_adj_lumi_cgtimes_node001 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su2_fun_lumi_cgtimes_node001 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su3_fun_lumi_cgtimes_node001 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]


#print(df_su2_adj_lumi)

dataframe_representation_lst_lumi = [df_su2_adj_lumi, df_su2_fun_lumi, df_su3_fun_lumi]

#rc = plot_representation_matplotlib(c, m, dataframe_representation_lst_lumi, machine_name_lumi)

df_su2_adj_lumi_cgtimes_mpi = df_su2_adj_lumi[["mpi_distribution","CG Run Time (s)","nodes"]]
df_su2_fun_lumi_cgtimes_mpi = df_su2_fun_lumi[["mpi_distribution","CG Run Time (s)","nodes"]]
df_su3_fun_lumi_cgtimes_mpi = df_su3_fun_lumi[["mpi_distribution","CG Run Time (s)","nodes"]]

#print(df_su2_adj_lumi_cgtimes_mpi)


df_su2_adj_lumi_cgtimes_mpi_node001 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)","mpi_distribution"]]
df_su2_adj_lumi_cgtimes_mpi_node002 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)","mpi_distribution"]]

df_su2_fun_lumi_cgtimes_mpi_node001 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)","mpi_distribution"]]
df_su2_fun_lumi_cgtimes_mpi_node002 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)","mpi_distribution"]]

df_su3_fun_lumi_cgtimes_mpi_node001 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)","mpi_distribution"]]
df_su3_fun_lumi_cgtimes_mpi_node002 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "002"][["CG Run Time (s)","mpi_distribution"]]


df_su2_adj_lumi_mpi_node001     = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["mpi_distribution"]]
df_su2_adj_lumi_cgtimes_node001 = df_su2_adj_lumi_cgtimes_mpi[df_su2_adj_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su2_fun_lumi_cgtimes_node001 = df_su2_fun_lumi_cgtimes_mpi[df_su2_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]
df_su3_fun_lumi_cgtimes_node001 = df_su3_fun_lumi_cgtimes_mpi[df_su3_fun_lumi_cgtimes_mpi["nodes"] == "001"][["CG Run Time (s)"]]



print(df_su2_adj_lumi_mpi_node001)

print(df_su2_adj_lumi_mpi_node001['mpi_distribution'])

print(df_su2_adj_lumi_cgtimes_node001)

rc = plot_groupByBars_matplotlib(c, m)

print(df_su2_adj_lumi_cgtimes_mpi_node001 )



dataframe_representation_cgtimes_mpi_lst_lumi = [df_su2_adj_lumi_cgtimes_mpi] #,df_su3_fun_lumi_cgtimes_mpi, df_su4_fun_lumi_cgtimes_mpi]

rc = plot_representation_seaborn(c, m, dataframe_representation_cgtimes_mpi_lst_lumi, machine_name_lumi)
rc = plot_representation_seaborn(c, m, [df_su2_adj_lumi_cgtimes_mpi_node001], machine_name_lumi, "node001")
rc = plot_representation_seaborn(c, m, [df_su2_adj_lumi_cgtimes_mpi_node002], machine_name_lumi, "node002")

print(df_su2_adj_lumi, df_su2_fun_lumi, df_su3_fun_lumi)




def plot_BenchRes_groupByBars_matplotlib(c, m,
                                         df_mpi_distr,
                                         df_su2_adj,
                                         df_su2_fun,
                                         df_su3_fun,
                                         mach_name, message):
    __func__ = sys._getframe().f_code.co_name
    rc = c.get_RC_SUCCESS()
    m.printMesgStr("Getting target file list      :", c.getGreen(), __func__)

    # Extract MPI distributions
    species = tuple(df_mpi_distr)

    # Dictionary containing data series
    grouped_data = {
        'SU(2) Adj': df_su2_adj,
        'SU(2) Fun': df_su2_fun,
        'SU(3) Fun': df_su3_fun,
    }

    colors = ['blue', 'red', 'green']
    x = np.arange(len(species))  # Label locations
    width = 0.25  # Adjusted bar width
    multiplier = 0

    fig, ax = plt.subplots(layout='constrained', figsize=(16, 10))

    for (attribute, measurement), color in zip(grouped_data.items(), colors):
        offset = width * multiplier
        rects = ax.bar(x + offset, measurement, width, label=attribute, color=color)
        ax.bar_label(rects, padding=3)
        multiplier += 1

    # Set labels and title
    ax.set_ylabel('CG Run Time (s)')
    ax.set_xlabel('MPI distribution')
    ax.set_title(f"[{mach_name}] {message}")

    # Set x-axis ticks
    ax.set_xticks(x + width)
    ax.set_xticklabels(species, rotation=45, ha='right')

    ax.legend(loc='upper left', ncols=3)

    plt.show()
    return rc



https://indico.cern.ch/event/1466097/
https://edbennett.github.io/exatepp-talk-20241112/


start_key_rep_lst = [
    'Performing benchmark for SU(2), adjoint',
    'Performing benchmark for SU(2), fundamental',
    'Performing benchmark for SU(3), fundamental',
    'Performing benchmark for Sp(4), fundamental'
]
print ("start_key_rep_lst[:]       --->: ", start_key_rep_lst[:] )
print ("len(start_key_rep_lst[:])  --->: ", len(start_key_rep_lst[:]) )



#start_key_rep_ith = start_key_rep_lst[ikey]
#cnt = 0
#for ikey in range(len(start_key_rep_lst[:])):
#ikey = 0
#start_key_rep_ith = start_key_rep_lst[ikey]
#appending = False
#print (start_key_rep_lst[ikey])
#print("j --->: ", j)
#if start_key_rep_lst[ikey] in lines[j].split('\n')[0]:
#    appending = True
#if end_key_rep in lines[j].split('\n')[0]:
#    appending = False
#if ikey + 1 < len(start_key_rep_lst[:]):
#    if start_key_rep_lst[ikey+1] in lines[j].split('\n')[0]:
#        appending = True
#elif ikey + 1 = len(start_key_rep_lst[:]):
#elif appending:
#rc, cg_run_time_lst, FlOps_GFlOps_lst, Comms_MB_lst, Memory_GB_lst, mpi_distribution_lst, nnodes_lst, lattice_size_lst, representation_lst =

print (start_key_rep_lst[:])
print (len(start_key_rep_lst[:]))
print ("representation_lst[:]      --->: ", representation_lst[:] )
print ("len(representation_lst[:]) --->: ", len(representation_lst[:]) )


ikey = 1
start_key_rep_ith = start_key_rep_lst[ikey]
appending = False
print (start_key_rep_lst[ikey])
for j in range(database_file_len):
    #print("j --->: ", j)
    if start_key_rep_lst[ikey] in lines[j].split('\n')[0]:
        appending = True
    if end_key_rep in lines[j].split('\n')[0]:
        appending = False
    #if ikey + 1 < len(start_key_rep_lst[:]):
    #    if start_key_rep_lst[ikey+1] in lines[j].split('\n')[0]:
    #        appending = True
    #elif ikey + 1 = len(start_key_rep_lst[:]):
    elif appending:

        rc, cg_run_time_lst, FlOps_GFlOps_lst, Comms_MB_lst, Memory_GB_lst, mpi_distribution_lst, nnodes_lst, lattice_size_lst, representation_lst = extract_dataframes_from_representation(
            c, lines[j], split_string,
            start_key_rep_lst[ikey],
            cg_run_time_lst, FlOps_GFlOps_lst,
            Comms_MB_lst, Memory_GB_lst,
            mpi_distribution_lst, nnodes_lst,
            lattice_size_lst, representation_lst
        )
    # [end-if]
# [end-for-loop [ikey]]



def read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_lst):
    __func__= sys._getframe().f_code.co_name
    rc = c.get_RC_SUCCESS()
    m.printMesgStr("Getting target file list      :", c.getGreen(), __func__)
    end_key_rep = "###############################################"
    bench_BKeeper_dict = {}
    start_key_rep_lst = [
        'Performing benchmark for SU(2), adjoint',
        'Performing benchmark for SU(2), fundamental',
        'Performing benchmark for SU(3), fundamental',
        'Performing benchmark for Sp(4), fundamental'
    ]
    start_bkeeper_key = "BKeeper"
    # Starting the parsing of files over the start_key_lst
    # TODO: loop over the representation key
    #ikey = 0
    cg_run_time_lst = []
    FlOps_GFlOps_lst = []
    Comms_MB_lst = []
    Memory_GB_lst = []
    mpi_distribution_lst = []
    nnodes_lst = []
    lattice_size_lst = []
    representation_lst = []
    # Making sure that the list are empty before inserting anything
    cg_run_time_lst.clear()
    FlOps_GFlOps_lst.clear()
    Comms_MB_lst.clear()
    Memory_GB_lst.clear()
    mpi_distribution_lst.clear()
    nnodes_lst.clear()
    lattice_size_lst.clear()
    representation_lst.clear()
    #
    print (start_key_rep_lst[:])
    print (len(start_key_rep_lst[:]))
    for i in range(6): #tqdm.tqdm(range(len(target_file_cluster_lst[:])), ncols=100, desc='bench_BKeeper_dict'):
        #for i in range(len(target_file_cluster_lst[:])):
        cluster_file = open(target_file_cluster_lst[i])
        # Getting the mpi_distribution, lattice size and number of nodes
        ith_file = os.path.basename(target_file_cluster_lst[i].split('\n')[0]).split('.out')[0].split('Run_')[1].split(batch_action+'_')[1].split('_'+simulation_size)[0]
        split_string = ith_file.split('_')

        lines = cluster_file.readlines()
        database_file_len = len(lines)
        #start_key_rep_ith = start_key_rep_lst[ikey]
        #cnt = 0
        for ikey in range(len(start_key_rep_lst[:])):
            #ikey = 0
            start_key_rep_ith = start_key_rep_lst[ikey]
            appending = False
            print (start_key_rep_lst[ikey])

            for j in range(database_file_len):
                #print("j --->: ", j)
                if start_key_rep_lst[ikey] in lines[j].split('\n')[0]:
                    appending = True
                if end_key_rep in lines[j].split('\n')[0]:
                    appending = False
                if ikey + 1 < len(start_key_rep_lst[:]):
                    if start_key_rep_lst[ikey+1] in lines[j].split('\n')[0]:
                        appending = False
                #elif ikey + 1 = len(start_key_rep_lst[:]):

                elif appending:

                    rc = extract_dataframes_from_representation(
                        c, lines[j], split_string,
                        start_key_rep_lst[ikey],
                        cg_run_time_lst, FlOps_GFlOps_lst,
                        Comms_MB_lst, Memory_GB_lst,
                        mpi_distribution_lst, nnodes_lst,
                        lattice_size_lst, representation_lst
                    )
                # [end-if]
            # [end-for-loop [ikey]]

        # [end-for-loop [j]]
    # [end-for-loop [i]]
    bench_BKeeper_dict["Representation"]   = representation_lst[:]
    bench_BKeeper_dict["CG Run Time (s)"]  = cg_run_time_lst[:]
    bench_BKeeper_dict["FlOp/S (GFlOp/s)"] = FlOps_GFlOps_lst[:]
    bench_BKeeper_dict["Comms  (MB)"]      = Comms_MB_lst[:]
    bench_BKeeper_dict["Memory (GB)"]      = Memory_GB_lst[:]
    bench_BKeeper_dict["lattice"]          = lattice_size_lst[:]
    bench_BKeeper_dict["nodes"]            = nnodes_lst[:]
    bench_BKeeper_dict["mpi_distribution"] = mpi_distribution_lst[:]

    # creating a dictionary from the output data
    #print(" printing the dictionay ---->: ", bench_BKeeper_dict)
    dataframe = pandas.DataFrame.from_dict(bench_BKeeper_dict)

    return rc, dataframe
# [end-function]
# --------------------------------------------------------------------------




def extract_dataframes_from_representation(c, m, j, lines, split_string,
                                           start_key_rep_ith, end_key_rep,
                                           appending,
                                           cg_run_time_lst,
                                           FlOps_GFlOps_lst,
                                           Comms_MB_lst,
                                           Memory_GB_lst,
                                           mpi_distribution_lst,
                                           nnodes_lst,
                                           lattice_size_lst,
                                           representation_lst):
    __func__= sys._getframe().f_code.co_name
    rc = c.get_RC_SUCCESS()
    #m.printMesgStr("Getting target file list      :", c.getGreen(), __func__)
    # ----------------------------------------------------------------------
    start_bkeeper_key = "BKeeper"

    if start_key_rep_ith in lines[j].split('\n')[0]:
        appending = True
    if end_key_rep in lines[j].split('\n')[0]:
        appending = False
    elif appending:
        if start_bkeeper_key in lines[j].split('\n')[0]:
            if "CG Run Time (s)" in  lines[j].split('\n')[0]:
                key   = "CG Run Time (s)" #str(lines[j]).split(':')[0]
                value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                cg_run_time_lst.append(float(value))

                lattice_size_lst.append(str(split_string[0]).split('lat'  )[1])
                mpi_distribution_lst.append(str(split_string[2]).split('mpi'  )[1])
                nnodes_lst.append(str(split_string[1]).split('nodes')[1])
                representation_lst.append(str(start_key_rep_ith).split('Performing benchmark for ')[1])

            if "FlOp/S (GFlOp/s)" in  lines[j].split('\n')[0]:
                key   = "FlOp/S (GFlOp/s)" #str(lines[j]).split(':')[0]
                value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                FlOps_GFlOps_lst.append(float(value))
            if "Comms  (MB)" in  lines[j].split('\n')[0]:
                key   = "Comms" #str(lines[j]).split(':')[0]
                value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                Comms_MB_lst.append(float(value))
            if "Memory (GB)" in  lines[j].split('\n')[0]:
                key   = "Memory (GB)" #str(lines[j]).split(':')[0]
                value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                Memory_GB_lst.append(float(value))
    # [end-if]
    # ----------------------------------------------------------------------
    return rc, appending
# [end-function]




def read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_lst):
    __func__= sys._getframe().f_code.co_name
    rc = c.get_RC_SUCCESS()
    m.printMesgStr("Getting target file list      :", c.getGreen(), __func__)
    end_key_rep = "###############################################"
    bench_BKeeper_dict = {}
    start_key_rep_lst = [
        'Performing benchmark for SU(2), adjoint',
        'Performing benchmark for SU(2), fundamental',
        'Performing benchmark for SU(3), fundamental',
        'Performing benchmark for Sp(4), fundamental'
    ]
    start_bkeeper_key = "BKeeper"
    # Starting the parsing of files over the start_key_lst
    # TODO: loop over the representation key
    ikey = 0
    cg_run_time_lst = []
    FlOps_GFlOps_lst = []
    Comms_MB_lst = []
    Memory_GB_lst = []
    mpi_distribution_lst = []
    nnodes_lst = []
    lattice_size_lst = []
    representation_lst = []
    # Making sure that the list are empty before inserting anything
    cg_run_time_lst.clear()
    FlOps_GFlOps_lst.clear()
    Comms_MB_lst.clear()
    Memory_GB_lst.clear()
    mpi_distribution_lst.clear()
    nnodes_lst.clear()
    lattice_size_lst.clear()
    representation_lst.clear()
    #
    for i in tqdm.tqdm(range(len(target_file_cluster_lst[:])), ncols=100, desc='bench_BKeeper_dict'):
        #for i in range(len(target_file_cluster_lst[:])):
        cluster_file = open(target_file_cluster_lst[i])
        # Getting the mpi_distribution, lattice size and number of nodes
        ith_file = os.path.basename(target_file_cluster_lst[i].split('\n')[0]).split('.out')[0].split('Run_')[1].split(batch_action+'_')[1].split('_'+simulation_size)[0]
        split_string = ith_file.split('_')

        lines = cluster_file.readlines()
        database_file_len = len(lines)
        start_key_rep_ith = start_key_rep_lst[ikey]
        appending = False
        cnt = 0
        for j in range(database_file_len):
            if start_key_rep_ith in lines[j].split('\n')[0]:
                appending = True
            if end_key_rep in lines[j].split('\n')[0]:
                appending = False
            elif appending:
                if start_bkeeper_key in lines[j].split('\n')[0]:
                    if "CG Run Time (s)" in  lines[j].split('\n')[0]:
                        key   = "CG Run Time (s)" #str(lines[j]).split(':')[0]
                        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                        cg_run_time_lst.append(float(value))

                        lattice_size_lst.append(str(split_string[0]).split('lat'  )[1])
                        mpi_distribution_lst.append(str(split_string[2]).split('mpi'  )[1])
                        nnodes_lst.append(str(split_string[1]).split('nodes')[1])
                        representation_lst.append(str(start_key_rep_ith).split('Performing benchmark for ')[1])

                    if "FlOp/S (GFlOp/s)" in  lines[j].split('\n')[0]:
                        key   = "FlOp/S (GFlOp/s)" #str(lines[j]).split(':')[0]
                        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                        FlOps_GFlOps_lst.append(float(value))
                    if "Comms  (MB)" in  lines[j].split('\n')[0]:
                        key   = "Comms" #str(lines[j]).split(':')[0]
                        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                        Comms_MB_lst.append(float(value))
                    if "Memory (GB)" in  lines[j].split('\n')[0]:
                        key   = "Memory (GB)" #str(lines[j]).split(':')[0]
                        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
                        Memory_GB_lst.append(float(value))
            # [end-if]
        # [end-for-loop [j]]
    # [end-for-loop [i]]
    bench_BKeeper_dict["Representation"]   = representation_lst[:]
    bench_BKeeper_dict["CG Run Time (s)"]  = cg_run_time_lst[:]
    bench_BKeeper_dict["FlOp/S (GFlOp/s)"] = FlOps_GFlOps_lst[:]
    bench_BKeeper_dict["Comms  (MB)"]      = Comms_MB_lst[:]
    bench_BKeeper_dict["Memory (GB)"]      = Memory_GB_lst[:]
    bench_BKeeper_dict["lattice"]          = lattice_size_lst[:]
    bench_BKeeper_dict["nodes"]            = nnodes_lst[:]
    bench_BKeeper_dict["mpi_distribution"] = mpi_distribution_lst[:]

    # creating a dictionary from the output data
    #print(" printing the dictionay ---->: ", bench_BKeeper_dict)
    dataframe = pandas.DataFrame.from_dict(bench_BKeeper_dict)

    return rc, dataframe
# [end-function]
# --------------------------------------------------------------------------








import os

start_grid_key    = "Grid"


with open(target_file_cluster_lst[i]) as cluster_file:
nnodes = target_file_cluster_lst[i].split()
print(" target_file_cluster_lst["+str(i)+"] --->: ", ith_file )
 The list in question
print( " split_string --->: ", split_string)

print("<---->: "+ str(split_string[0]).split('lat'  )[1] +" <--->" + \
      str(split_string[1]).split('nodes')[1]  +" <--->" + \
        str(split_string[2]).split('mpi'  )[1] +"\n"
)

print("the number of lines in file "+ str(target_file_cluster_lst[i]) + " is : "+str(database_file_len))

print(lines[j].split('\n')[0])
# TODO: continue from here

print(lines[j].split('\n')[0])
if start_grid_key in lines[j].split('\n')[0]:
    if "Lattice dimensions" in lines[j].split('\n')[0]:
        print(" in Lattice dimensions")
        key   = "Lattice dimensions" #str(lines[j]).split(':')[0]
        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
        lattice_size_lst.append(value)
    if "MPI decomposition" in lines[j].split('\n')[0]:
        key   = "MPI decomposition" #str(lines[j]).split(':')[0]
        value = str(str(lines[j]).split(':')[4]).split('\n')[0]
        mpi_distribution_lst.append(value)
if target_file_cluster_lst[i].split('.sh')[0] in  lines[j].split('\n')[0]:
    value = str(split_string[1]).split('nodes')[1]
    nnodes_lst.append(value)


    #else:
    #    cg_run_time_lst.append('-')

    #else:
    #    cg_run_time_lst.append('-')
    #else:
    #    cg_run_time_lst.append('-')



    #else:
    #    cg_run_time_lst.append('-')




machine_name="Lumi"

APP_ROOT          = os.path.join(os.getcwd(), '..','..','..','..')
#DATA_PATH         = os.path.join(APP_ROOT, '.','src','PythonCodes','data','Lumi')
DATA_PATH         = os.path.join(APP_ROOT, '..','LatticeRuns','Clusters',machine_name,'LatticeRuns') #E:\LatticeRuns\Clusters

vega_path="sftp://eufredericb@login.vega.izum.si/ceph/hpc/home/eufredericb/SwanSea/SourceCodes/LatticeRuns/BKeeper_run_gpu/small/Run_BKeeper_run_gpu_lat24.24.24.32_nodes001_mpi01-01-04-01_small/Run_BKeeper_run_gpu_lat24.24.24.32_nodes001_mpi01-01-04-01_small.out"

os.system('cat %s'%vega_path)


# Reinitialising the paths and object content.
c.setData_path(DATA_PATH)
c.setTarget_File("target.txt")

target_file_default = c.getTarget_File()
m.printMesgStr("Default target file           :", c.getMagenta(), target_file_default)

msg_analysis = c.getTarget_File().split(".txt")[0] + c.undr_scr + \
               batch_action    + c.undr_scr                    + \
               simulation_size + c.undr_scr                    + \
               "batch_files"   + c.txt_ext

c.setTarget_File(str(msg_analysis))
m.printMesgStr("Target file for analysis      :", c.getMagenta(), c.getTarget_File())

c.setTargetdir( os.path.join(c.getData_path(), c.getTarget_File()))
m.printMesgStr("Full Path target file         :", c.getCyan(), c.getTargetdir())

if Path(c.getTargetdir()).is_file():
    m.printMesgAddStr("[Check]: target file       --->: ", c.getGreen(), "Exists")


