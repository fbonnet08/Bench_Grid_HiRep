{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Jupyter notebook Bench_Grid_HiRep starts\n",
    "---"
   ],
   "id": "f3314407852c666f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importing the packages and checking if they are on system.\n",
    "---"
   ],
   "id": "cf40e00640b4f26f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# [Python-3.12] basic import for system check\n",
    "# ----------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import multiprocessing\n",
    "import multiprocess\n",
    "from collections import defaultdict\n",
    "from functools import cache\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "# ----------------------------------------------------------------------------\n",
    "# [Data-Plotting]\n",
    "# ----------------------------------------------------------------------------\n",
    "try:\n",
    "    import numpy\n",
    "    NUMPY_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package numpy is not installed on your system, verify or install\\n\")\n",
    "    NUMPY_AVAILABLE = False\n",
    "try:\n",
    "    import matplotlib.pyplot\n",
    "    MATPLOTLIB_PYPLOT_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package matplotlib.pyplot is not installed on your system, verify or install\\n\")\n",
    "    MATPLOTLIB_PYPLOT_AVAILABLE = False\n",
    "try:\n",
    "    import matplotlib.colors\n",
    "    MATPLOTLIB_COLORS_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package matplotlib.colors is not installed on your system, verify or install\\n\")\n",
    "    MATPLOTLIB_COLORS_AVAILABLE = False\n",
    "try:\n",
    "    import matplotlib\n",
    "    MATPLOTLIB_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package matplotlib is not installed on your system, verify or install\\n\")\n",
    "    MATPLOTLIB_AVAILABLE = False\n",
    "try:\n",
    "    import tqdm\n",
    "    TQDM_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package tqdm is not installed on your system, verify or install\\n\")\n",
    "    TQDM_AVAILABLE = False\n",
    "try:\n",
    "    import pandas\n",
    "    PANDAS_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package pandas is not installed on your system, verify or install\\n\")\n",
    "    PANDAS_AVAILABLE = False\n",
    "try:\n",
    "    import seaborn\n",
    "    SEABORN_AVAILABLE = True\n",
    "except (ImportError, NameError, AttributeError, OSError):\n",
    "    print(\" Python package seaborn is not installed on your system, verify or install\\n\")\n",
    "    SEABORN_AVAILABLE = False\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "347a40e994d2ee41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Checking and printing check result\n",
    "---"
   ],
   "id": "83f3e916bebcf89f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# [Import-checks]\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\")\n",
    "print(\"MATPLOTLIB_AVAILABLE        --- installed --->: \", MATPLOTLIB_AVAILABLE)\n",
    "print(\"MATPLOTLIB_PYPLOT_AVAILABLE --- installed --->: \", MATPLOTLIB_PYPLOT_AVAILABLE)\n",
    "print(\"MATPLOTLIB_COLORS_AVAILABLE --- installed --->: \", MATPLOTLIB_COLORS_AVAILABLE)\n",
    "print(\"TQDM_AVAILABLE              --- installed --->: \", TQDM_AVAILABLE)\n",
    "print(\"PANDAS_AVAILABLE            --- installed --->: \", PANDAS_AVAILABLE)\n",
    "print(\"SEABORN_AVAILABLE           --- installed --->: \", SEABORN_AVAILABLE)\n",
    "print(\"NUMPY_AVAILABLE             --- installed --->: \", NUMPY_AVAILABLE)\n",
    "print(\"\\n\")\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "a174c5f2cb310f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting up the computation on the benchmark\n",
    "---"
   ],
   "id": "d714e4854b24887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "start_key_rep_lst = [\n",
    "    'Performing benchmark for SU(2), adjoint',\n",
    "    'Performing benchmark for SU(2), fundamental',\n",
    "    'Performing benchmark for SU(3), fundamental',\n",
    "    'Performing benchmark for Sp(4), fundamental'\n",
    "]\n",
    "start_key_sombrero_rep_lst = [\n",
    "    'Case 1:', 'Case 2:', 'Case 3:',\n",
    "    'Case 4:', 'Case 6:', 'Case 6:'\n",
    "]\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "1ec31eeec0fe992b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting up the main path structure and appending to system path.\n",
    "---"
   ],
   "id": "2a001c57e98aca59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# [Path]\n",
    "# ----------------------------------------------------------------------------\n",
    "current_path = str(Path(sys.path[0]) / \"..\")\n",
    "if current_path not in sys.path: sys.path.append(current_path)\n",
    "\n",
    "APP_ROOT          = os.path.join(os.getcwd(), '..','..','..','..')\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters')\n",
    "PROJECTNAME       = \"\"\n",
    "POOL_COMPONENTDIR = \"\"\n",
    "SOFTWARE          = \"N/A\"\n",
    "SQL_DIR           = 'SQLFiles_sql'\n",
    "APP_DATA_PATH     = \"N/A\"\n",
    "\n",
    "DATAPROCINTERCOM  = \"\"\n",
    "TBLECNTS_DIR      = \"\"\n",
    "SQL_FULLPATH_DIR  = os.path.join(os.getcwd())\n",
    "# ----------------------------------------------------------------------------\n",
    "# [SystemPath-Appens]\n",
    "# ----------------------------------------------------------------------------\n",
    "sys.path.append(APP_ROOT)\n",
    "sys.path.append(APP_DATA_PATH)\n",
    "sys.path.append(DATA_PATH)\n",
    "sys.path.append(os.path.join(APP_ROOT, '.'))\n",
    "sys.path.append(os.path.join(APP_ROOT, '.','src','PythonCodes'))\n",
    "sys.path.append(os.path.join(APP_ROOT, '.','src','PythonCodes','utils'))\n",
    "\n",
    "print(\"Current Path  --->: \", current_path)\n",
    "print(\"APP_ROOT      --->: \", APP_ROOT)\n",
    "print(\"DATA_PATH     --->: \", DATA_PATH)\n",
    "print(\"APP_DATA_PATH --->: \", APP_DATA_PATH)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "2357a002a87e851d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importing the application objects.\n",
    "---"
   ],
   "id": "ef2ea9b5a0e380e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# [Application]\n",
    "# ----------------------------------------------------------------------------\n",
    "#Application imports\n",
    "import src.PythonCodes.DataManage_common\n",
    "import src.PythonCodes.utils.messageHandler\n",
    "import src.PythonCodes.utils.Command_line\n",
    "import src.PythonCodes.DataManage_header\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "c8bffc4b1eb4e35a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Instantiating the main objects\n",
    "---"
   ],
   "id": "13cda1433c4de033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "version = src.PythonCodes.DataManage_common.DataManage_version()\n",
    "c = src.PythonCodes.DataManage_common.DataManage_common()\n",
    "rc = c.get_RC_SUCCESS()\n",
    "# Getting the log file\n",
    "logfile = c.getLogfileName()  #getting the name of the global log file\n",
    "m = src.PythonCodes.utils.messageHandler.messageHandler(logfile = logfile)\n",
    "# printing the header of Application\n",
    "src.PythonCodes.DataManage_header.print_Bench_Grid_header(common=c, messageHandler=m)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "f262adb47028c616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting the path structure into the main objects\n",
    "---"
   ],
   "id": "5918e31a05a64741"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "c.setApp_root(APP_ROOT)\n",
    "c.setData_path(DATA_PATH)\n",
    "c.setProjectName(PROJECTNAME)\n",
    "c.setPool_componentdir(POOL_COMPONENTDIR)\n",
    "c.setSoftware(SOFTWARE)\n",
    "c.setDataProcInterCom(DATAPROCINTERCOM)\n",
    "c.setJSon_TableCounts_Dir(TBLECNTS_DIR)\n",
    "c.setSql_dir(SQL_DIR)\n",
    "c.setSql_fullPath_dir(SQL_FULLPATH_DIR)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "3e18dcaf2791ba29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Starting the program\n",
    "---"
   ],
   "id": "6c425fdee2527782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Main-code]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(\"This is the main program      :\", c.getCyan(), \"Bench_Grid_HiRep.py\")\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "f8f2cc71ad5de6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Main functions\n",
    "---"
   ],
   "id": "252445d80613b79f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reinitialising_Paths_and_object_content",
   "id": "bda5aeac975fdf38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def Reinitialising_Paths_and_object_content(c, m, data_path, b_action, sim_sz):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    c.setData_path(data_path)\n",
    "    c.setTarget_File(\"target.txt\")\n",
    "\n",
    "    target_file_default = c.getTarget_File()\n",
    "    m.printMesgStr(\"Default target file           :\", c.getMagenta(), target_file_default)\n",
    "\n",
    "    msg_analysis = c.getTarget_File().split(\".txt\")[0] + c.undr_scr + \\\n",
    "                    b_action      + c.undr_scr                      + \\\n",
    "                    sim_sz        + c.undr_scr                      + \\\n",
    "                    \"batch_files\" + c.txt_ext\n",
    "\n",
    "    c.setTarget_File(str(msg_analysis))\n",
    "    m.printMesgStr(\"Target file for analysis      :\", c.getMagenta(), c.getTarget_File())\n",
    "\n",
    "    c.setTargetdir( os.path.join(c.getData_path(), c.getTarget_File()))\n",
    "    m.printMesgStr(\"Full Path target file         :\", c.getCyan(), c.getTargetdir())\n",
    "\n",
    "    if Path(c.getTargetdir()).is_file():\n",
    "        m.printMesgAddStr(\"[Check]: target file       --->: \", c.getGreen(), \"Exists\")\n",
    "    # ----------------------------------------------------------------------\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "ecd3e0551bfff9a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### getTarget_file_lst",
   "id": "eda34a8a78543807"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def getTarget_file_lst(c, m, target_file):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    target_file_lst = []\n",
    "    target_file_dir = []\n",
    "    try:\n",
    "        with open(target_file) as file:\n",
    "            cnt = 0\n",
    "            for line in file:\n",
    "                target_file_lst.append(os.path.basename(line).strip())\n",
    "                target_file_dir.append(os.path.dirname(os.path.realpath(line)).strip())\n",
    "                cnt += 1\n",
    "            # [end-For-Loop]\n",
    "            m.printMesgAddStr(\"target_file filename           : \", c.getCyan(), str(target_file))\n",
    "            m.printMesgAddStr(\"Number of files in target_file : \", c.getYellow(), str(cnt))\n",
    "        # [end-with]\n",
    "    except IOError:\n",
    "        m.printMesgAddStr(\" Filename          : \", c.getCyan(), target_file)\n",
    "        m.printMesgAddStr(\"                   : \", c.getRed(), \"cannot be found check if file exist\")\n",
    "        #exit(c.get_RC_FAIL())\n",
    "    # [end-try-catch]\n",
    "    return rc, target_file_lst, target_file_dir\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "9bfba0bb3a31af5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### getTaget_file_cluster_lst",
   "id": "20f970374cad09d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def getTarget_file_cluster_lst(c, m, target_file_lst):\n",
    "    # TODO: must pass in batch_action in the argument list because in abstracted class\n",
    "    # TODO: it is a bug otherwise Sombrero_weak and Sombrero_weak_cpu is the problem\n",
    "    # TODO: or fixe the batch script production in the filename convention the script generation\n",
    "    # TODO: has it in memory that is why it works here and only here.\n",
    "    # TODO: If statement in junk.python file in case.\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    target_file_cluster_lst = []\n",
    "    for i in range(len(target_file_lst[:])):\n",
    "        msg = (os.path.join(c.getData_path(), batch_action, simulation_size, str(target_file_lst[i].split(\".sh\")[0]), target_file_lst[i])).strip()\n",
    "        if Path(msg).is_file():\n",
    "            m.printMesgAddStr(\"[Check]: target file       --->: \", c.getGreen(), c.getMagenta()+ msg + c.getGreen() + \" ---> Exists\")\n",
    "            # Now get the output file to analise and put it into a list\n",
    "            cluster_out_file = msg.split(\".sh\")[0]+\".out\"\n",
    "            # Extracting cluster files that has been benched\n",
    "            if Path(cluster_out_file).is_file():\n",
    "                m.printMesgAddStr(\"[Check]: Cluster file      --->: \", c.getGreen(), c.getYellow()+ cluster_out_file + c.getGreen() + \" ---> Exists\")\n",
    "                target_file_cluster_lst.append(cluster_out_file)\n",
    "            # [end-if]\n",
    "        # [end-if]\n",
    "    # [end-for-loop]\n",
    "    return rc, target_file_cluster_lst\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "867a9b93449cdcf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### extract_df_representation_BKeeper",
   "id": "b61842f777476517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def extract_df_representation_BKeeper(c, line,\n",
    "                                      split_string,\n",
    "                                      cg_run_time_lst,\n",
    "                                      FlOps_GFlOps_lst,\n",
    "                                      Comms_MB_lst,\n",
    "                                      Memory_GB_lst,\n",
    "                                      mpi_distribution_lst,\n",
    "                                      nnodes_lst,\n",
    "                                      lattice_size_lst,\n",
    "                                      representation_lst,\n",
    "                                      ith_target_filename,\n",
    "                                      run_file_name_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    #m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    start_bkeeper_key = \"BKeeper\"\n",
    "    if start_bkeeper_key in line.split('\\n')[0]:\n",
    "        if 'Performing benchmark for ' in line.split('\\n')[0]:\n",
    "            rep_value = str(line.split('\\n')[0]).split('Performing benchmark for ')[1].split(' #')[0]\n",
    "            #print(\"rep_value --->: \", rep_value)\n",
    "            if rep_value != 'Sp(4), fundamental':\n",
    "                representation_lst.append(rep_value)\n",
    "                run_file_name_lst.append(ith_target_filename)\n",
    "\n",
    "        if \"CG Run Time (s)\" in line.split('\\n')[0]:\n",
    "            key   = \"CG Run Time (s)\" #str(lines[j]).split(':')[0]\n",
    "            value = str(str(line).split(':')[4]).split('\\n')[0]\n",
    "            cg_run_time_lst.append(float(value))\n",
    "\n",
    "            lattice_size_lst.append(str(split_string[0]).split('lat'  )[1])\n",
    "            nnodes_lst.append(str(split_string[1]).split('nodes')[1])\n",
    "            mpi_distribution_lst.append(str(split_string[2]).split('mpi'  )[1])\n",
    "            #if rep_value != \"empty_string\":\n",
    "\n",
    "        if \"FlOp/S (GFlOp/s)\" in line.split('\\n')[0]:\n",
    "            key   = \"FlOp/S (GFlOp/s)\" #str(lines[j]).split(':')[0]\n",
    "            value = str(str(line).split(':')[4]).split('\\n')[0]\n",
    "            FlOps_GFlOps_lst.append(float(value))\n",
    "        if \"Comms  (MB)\" in  line.split('\\n')[0]:\n",
    "            key   = \"Comms\" #str(lines[j]).split(':')[0]\n",
    "            value = str(str(line).split(':')[4]).split('\\n')[0]\n",
    "            Comms_MB_lst.append(float(value))\n",
    "        if \"Memory (GB)\" in line.split('\\n')[0]:\n",
    "            key   = \"Memory (GB)\" #str(lines[j]).split(':')[0]\n",
    "            value = str(str(line).split(':')[4]).split('\\n')[0]\n",
    "            Memory_GB_lst.append(float(value))\n",
    "    # [end-if]\n",
    "    # ----------------------------------------------------------------------\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "9cc6e6b3db817e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### extract_df_representation_Sombrero",
   "id": "1f7e10e098ae0b63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def extract_df_representation_Sombrero(c, line, split_string,\n",
    "                                       nnodes_lst,\n",
    "                                       ntpns_lst,\n",
    "                                       case_lst,\n",
    "                                       Gflops_per_seconds_lst,\n",
    "                                       Gflops_in_seconds_lst,\n",
    "                                       lattice_sz_value,\n",
    "                                       lattice_sz_lst,\n",
    "                                       ith_target_filename,\n",
    "                                       run_file_name_sombrero_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    #m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    #start_sombrero_key = \"[MAIN][0]SOMBRERO built from HiRep commit\"\n",
    "    start_case1_key = \"Case 1\"\n",
    "    #if start_sombrero_key in line.split('\\n')[0]:\n",
    "    # TODO: Lattice volume, parallelisation, and GFLOP/s for each test would be the minimum.\n",
    "    if '[RESULT][0] Case 1' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case1_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 1')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 1')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    start_case2_key = \"Case 2\"\n",
    "    if '[RESULT][0] Case 2' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case2_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 2')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 2')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    start_case3_key = \"Case 3\"\n",
    "    if '[RESULT][0] Case 3' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case3_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 3')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 3')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    start_case4_key = \"Case 4\"\n",
    "    if '[RESULT][0] Case 4' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case4_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 4')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 4')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    start_case5_key = \"Case 5\"\n",
    "    if '[RESULT][0] Case 5' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case4_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 5')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 5')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    start_case6_key = \"Case 6\"\n",
    "    if '[RESULT][0] Case 6' in line.split('\\n')[0]:\n",
    "        if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "            #print(line.split('\\n')[0])\n",
    "            case_lst.append(start_case4_key)\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 6')[1].split('Gflops/seconds')[0]\n",
    "            Gflops_per_seconds_lst.append(value)\n",
    "            nnodes_lst.append(str(split_string[0]).split('nodes')[1])\n",
    "            ntpns_lst.append(str(split_string[1]).split('ntpns')[1])\n",
    "            lattice_sz_lst.append(str(lattice_sz_value))\n",
    "            run_file_name_sombrero_lst.append(ith_target_filename)\n",
    "        # [end-if]\n",
    "        if 'Gflops in' in line.split('\\n')[0]:\n",
    "            value = str(line.split('\\n')[0]).split('[RESULT][0] Case 6')[1].split('seconds')[0]\n",
    "            Gflops_in_seconds_lst.append(value)\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    # ----------------------------------------------------------------------\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "c224d6f4952bc65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get number of representation in the raget file",
   "id": "2e3eb4c267be3453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def get_target_file_cluster_usable(c, nrep, line):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    #m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    start_bkeeper_key = \"BKeeper\"\n",
    "    if start_bkeeper_key in line.split('\\n')[0]:\n",
    "        if 'Performing benchmark for ' in line.split('\\n')[0]:\n",
    "            nrep += 1\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Sombrero filter\n",
    "    start_sombrero_key = \"[MAIN][0]SOMBRERO built from HiRep commit\"\n",
    "    if start_sombrero_key in line.split('\\n')[0]:\n",
    "        #if 'Gflops/seconds' in line.split('\\n')[0]:\n",
    "        if '[RESULT][0] Case' in line.split('\\n')[0]:\n",
    "            nrep += 1\n",
    "            # [end-if]\n",
    "        # [end-if]\n",
    "    # [end-if]\n",
    "    # ----------------------------------------------------------------------\n",
    "    return rc, nrep\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "6fbe0d94ffdea219",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### read_BKeeper_file_out",
   "id": "1c31dc890566573d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def read_BKeeper_file_out(c, m, batch_act, sim_size, target_file_cluster_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    bench_BKeeper_dict = {}\n",
    "    # list definitions\n",
    "    cg_run_time_lst = []\n",
    "    FlOps_GFlOps_lst = []\n",
    "    Comms_MB_lst = []\n",
    "    Memory_GB_lst = []\n",
    "    mpi_distribution_lst = []\n",
    "    nnodes_lst = []\n",
    "    lattice_size_lst = []\n",
    "    representation_lst = []\n",
    "    run_file_name_lst = []\n",
    "    # Making sure that the list are empty before inserting anything\n",
    "    cg_run_time_lst.clear()\n",
    "    FlOps_GFlOps_lst.clear()\n",
    "    Comms_MB_lst.clear()\n",
    "    Memory_GB_lst.clear()\n",
    "    mpi_distribution_lst.clear()\n",
    "    nnodes_lst.clear()\n",
    "    lattice_size_lst.clear()\n",
    "    representation_lst.clear()\n",
    "    run_file_name_lst.clear()\n",
    "    #\n",
    "    #for i in range(6):\n",
    "    for i in tqdm.tqdm(range(len(target_file_cluster_lst[:])), ncols=100, desc='bench_BKeeper_dict'):\n",
    "        #for i in range(len(target_file_cluster_lst[:])):\n",
    "        try:\n",
    "            if len(target_file_cluster_lst[:]) != 0:\n",
    "                cluster_file = open(target_file_cluster_lst[i])\n",
    "                # Getting the mpi_distribution, lattice size and number of nodes\n",
    "                ith_file = os.path.basename(target_file_cluster_lst[i].split('\\n')[0]).split('.out')[0].split('Run_')[1].split(batch_act+'_')[1].split('_'+sim_size)[0]\n",
    "                split_string = ith_file.split('_')\n",
    "                lines = cluster_file.readlines()\n",
    "                database_file_len = len(lines)\n",
    "                for j in range(database_file_len):\n",
    "                    rc = extract_df_representation_BKeeper(c, lines[j], split_string,\n",
    "                                                           cg_run_time_lst, FlOps_GFlOps_lst,\n",
    "                                                           Comms_MB_lst, Memory_GB_lst,\n",
    "                                                           mpi_distribution_lst, nnodes_lst,\n",
    "                                                           lattice_size_lst, representation_lst,\n",
    "                                                           target_file_cluster_lst[i], run_file_name_lst)\n",
    "                # [end-for-loop [j]]\n",
    "            # [end-if]\n",
    "        except IOError:\n",
    "            m.printMesgAddStr(\" Filename          : \", c.getCyan(), target_file_cluster_lst[i])\n",
    "            m.printMesgAddStr(\"                   : \", c.getRed(), \"cannot be found check if file exist\")\n",
    "        # [end-try-catch]\n",
    "    # [end-for-loop [i]]\n",
    "\n",
    "    bench_BKeeper_dict[\"Representation\"]   = representation_lst[:]\n",
    "    bench_BKeeper_dict[\"CG Run Time (s)\"]  = cg_run_time_lst[:]\n",
    "    bench_BKeeper_dict[\"FlOp/S (GFlOp/s)\"] = FlOps_GFlOps_lst[:]\n",
    "    bench_BKeeper_dict[\"Comms  (MB)\"]      = Comms_MB_lst[:]\n",
    "    bench_BKeeper_dict[\"Memory (GB)\"]      = Memory_GB_lst[:]\n",
    "    bench_BKeeper_dict[\"lattice\"]          = lattice_size_lst[:]\n",
    "    bench_BKeeper_dict[\"nodes\"]            = nnodes_lst[:]\n",
    "    bench_BKeeper_dict[\"mpi_distribution\"] = mpi_distribution_lst[:]\n",
    "    bench_BKeeper_dict[\"Run output file\"]  = run_file_name_lst[:]\n",
    "\n",
    "    # creating a dictionary from the output data\n",
    "    dataframe = pandas.DataFrame.from_dict(bench_BKeeper_dict)\n",
    "\n",
    "    # Now sorting out the data from on the mpi_distribution column.\n",
    "    dataframe.sort_values(by='mpi_distribution', inplace=True)\n",
    "\n",
    "    return rc, dataframe\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "efe6a79aebed5971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### read_Sombrero_file_out",
   "id": "b0b37d473ac4e02e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def read_Sombrero_file_out(c, m, batch_act, sim_size, target_file_cluster_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    bench_Sombrero_dict = {}\n",
    "    # list definitions\n",
    "    nnodes_lst = []\n",
    "    ntpns_lst = []\n",
    "    case_lst = []\n",
    "    Gflops_per_seconds_lst = []\n",
    "    Gflops_in_seconds_lst = []\n",
    "    lattice_sz_lst = []\n",
    "    run_file_name_sombrero_lst = []\n",
    "    # Making sure that the list are empty before inserting anything\n",
    "    nnodes_lst.clear()\n",
    "    ntpns_lst.clear()\n",
    "    case_lst.clear()\n",
    "    Gflops_per_seconds_lst.clear()\n",
    "    Gflops_in_seconds_lst.clear()\n",
    "    lattice_sz_lst.clear()\n",
    "    run_file_name_sombrero_lst.clear()\n",
    "    #\n",
    "    #for i in range(6):\n",
    "    for i in tqdm.tqdm(range(len(target_file_cluster_lst[:])), ncols=100, desc='bench_BKeeper_dict'):\n",
    "        try:\n",
    "            if len(target_file_cluster_lst[:]) != 0:\n",
    "                cluster_file = open(target_file_cluster_lst[i])\n",
    "                ith_file = os.path.basename(target_file_cluster_lst[i].split('\\n')[0]).split('.out')[0].split('Run_')[1].split(batch_act+'_')[1].split('_'+sim_size)[0]\n",
    "                split_string = ith_file.split('_')\n",
    "                lines = cluster_file.readlines()\n",
    "                database_file_len = len(lines)\n",
    "                lattice_sz_value = \"not reported\"\n",
    "                for j in range(database_file_len):\n",
    "                    start_lattice_key = \"[GEOMETRY][10] Global size is\"\n",
    "                    if start_lattice_key in lines[j].split('\\n')[0]:\n",
    "                        lattice_sz_value = str(lines[j].split('\\n')[0]).split(start_lattice_key)[1]\n",
    "                    # [end-if]\n",
    "                # [end-for-loop [j]]\n",
    "                for j in range(database_file_len):\n",
    "                    rc = extract_df_representation_Sombrero(c, lines[j], split_string,\n",
    "                                                            nnodes_lst,\n",
    "                                                            ntpns_lst,\n",
    "                                                            case_lst,\n",
    "                                                            Gflops_per_seconds_lst,\n",
    "                                                            Gflops_in_seconds_lst,\n",
    "                                                            lattice_sz_value,\n",
    "                                                            lattice_sz_lst,\n",
    "                                                            target_file_cluster_lst[i], run_file_name_sombrero_lst)\n",
    "                # [end-for-loop [j]]\n",
    "            # [end-if]\n",
    "        except IOError:\n",
    "            m.printMesgAddStr(\" Filename          : \", c.getCyan(), target_file_cluster_lst[i])\n",
    "            m.printMesgAddStr(\"                   : \", c.getRed(), \"cannot be found check if file exist\")\n",
    "        # [end-try-catch]\n",
    "    # [end-for-loop [i]]\n",
    "\n",
    "    print(len(lattice_sz_lst[:]))\n",
    "    print(len(case_lst[:]))\n",
    "    print(len(run_file_name_sombrero_lst[:]))\n",
    "    print(len(Gflops_in_seconds_lst[:]))\n",
    "\n",
    "    bench_Sombrero_dict[\"Case\"]               = case_lst[:]\n",
    "    bench_Sombrero_dict[\"nodes\"]              = nnodes_lst[:]\n",
    "    bench_Sombrero_dict[\"ntpns\"]              = ntpns_lst[:]\n",
    "    bench_Sombrero_dict[\"Gflops_per_seconds\"] = Gflops_per_seconds_lst[:]\n",
    "    bench_Sombrero_dict[\"Gflops_in_seconds\"]  = Gflops_in_seconds_lst[:]\n",
    "    bench_Sombrero_dict[\"lattice_sz\"]         = lattice_sz_lst[:]\n",
    "    bench_Sombrero_dict[\"Run output file\"]    = run_file_name_sombrero_lst[:]\n",
    "\n",
    "    # creating a dictionary from the output data\n",
    "    dataframe = pandas.DataFrame.from_dict(bench_Sombrero_dict)\n",
    "\n",
    "    # Now sorting out the data from on the mpi_distribution column.\n",
    "    dataframe.sort_values(by=['Case', 'nodes', 'ntpns'], inplace=True)\n",
    "\n",
    "    return rc, dataframe\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "4ed764f71165a7e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### getDataFrame_from_Sombrero_Runs",
   "id": "1a48d79c50373967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def getDataFrame_from_Sombrero_Runs(c, m,\n",
    "                                    data_path, mach_name,\n",
    "                                    target_batch_act,\n",
    "                                    batch_act,\n",
    "                                    sim_size, start_key_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    #batch_action = \"Sombrero_weak_cpu\"\n",
    "    #simulation_size = \"small\"\n",
    "    rc = Reinitialising_Paths_and_object_content(c, m, data_path, target_batch_act, sim_size)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Getting content in the target file\n",
    "    # TODO: redefinition necessary to to act on the target file name _cpu\n",
    "    # TODO: and batch script discrepancy, batch action will need to be passed in,\n",
    "    # TODO: in the cluster method.\n",
    "    #batch_action = \"Sombrero_weak\"\n",
    "    rc, target_file_lst, target_file_dir = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Getting content in the target file\n",
    "    rc, target_file_cluster_lst = getTarget_file_cluster_lst(c, m, target_file_lst[:])\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # [Data-Extraction]\n",
    "    # --------------------------------------------------------------------------\n",
    "    m.printMesgStr(   \"Data extraction cluster out           : \", c.getGreen(), mach_name)\n",
    "    m.printMesgAddStr(\"Simulation size                       : \", c.getRed(), sim_size)\n",
    "    m.printMesgAddStr(\"target_file_cluster_lst[:]        --->: \", c.getYellow(), target_file_cluster_lst[:])\n",
    "    m.printMesgAddStr(\"Length target_file_cluster_lst[:] --->: \", c.getYellow(), len(target_file_cluster_lst[:]))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Reading in the inout file\n",
    "    # TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "    rc, target_file_cluster_filtered_lst = filter_target_file_cluster_lst(c, m,\n",
    "                                                                          start_key_lst[:],\n",
    "                                                                          target_file_cluster_lst[:])\n",
    "    m.printMesgAddStr(\"len(target_Sombrero_weak_small_file_cluster_filtered_lst[:]) --->: \",\n",
    "                      c.getYellow(), len(target_file_cluster_filtered_lst[:]))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Reading in the inout file\n",
    "    # TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "    msg = batch_act + \"_\" + sim_size + \"_\" + \"all nodes\"\n",
    "    rc, file_cluster_failed_lst = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                   target_file_cluster_lst[:],\n",
    "                                                                                   target_file_cluster_filtered_lst[:],\n",
    "                                                                                   mach_name,\n",
    "                                                                                   msg)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Reading in the inout file\n",
    "    # TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "    # TODO: instead. For now we are going to use the full unfiltered list.\n",
    "    #batch_action = \"Sombrero_weak\"\n",
    "    #simulation_size = \"small\"\n",
    "    rc, dataframe = read_Sombrero_file_out(c, m,\n",
    "                                           batch_act, sim_size,\n",
    "                                           target_file_cluster_lst)\n",
    "    # --------------------------------------------------------------------------\n",
    "    return rc, dataframe\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "b541e95e858997df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### filter_target_file_cluster_lst",
   "id": "7f4934d19162b49e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def filter_target_file_cluster_lst(c, m, key_rep_lst, target_file_cluster_lst):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(   \"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    target_file_cluster_filtered_lst = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(target_file_cluster_lst[:])), ncols=100, desc='filter target file'):\n",
    "        #for i in range(len(target_file_cluster_lst[:])):\n",
    "        try:\n",
    "            if len(target_file_cluster_lst[:]) != 0:\n",
    "                cluster_file = open(target_file_cluster_lst[i])\n",
    "                # Getting the mpi_distribution, lattice size and number of nodes\n",
    "                #ith_file = os.path.basename(target_file_cluster_lst[i].split('\\n')[0]).split('.out')[0].split('Run_')[1].split(batch_action+'_')[1].split('_'+simulation_size)[0]\n",
    "                #split_string = ith_file.split('_')\n",
    "\n",
    "                lines = cluster_file.readlines()\n",
    "                database_file_len = len(lines)\n",
    "\n",
    "                #print(\"target_file_cluster_lst[i] -->: \", target_file_cluster_lst[i])\n",
    "                nrep = 0\n",
    "                for j in range(database_file_len):\n",
    "                    rc, nrep = get_target_file_cluster_usable(c, nrep, lines[j])\n",
    "                # [end-for-loop [j]]\n",
    "\n",
    "                #print(\"nrep ---->: \", nrep)\n",
    "                if nrep == len(key_rep_lst[:]):\n",
    "                    target_file_cluster_filtered_lst.append(target_file_cluster_lst[i])\n",
    "                # [end-if]\n",
    "                #m.printMesgAddStr(\" Cases benched in .out        : \", c.getCyan(), nrep)\n",
    "        except IOError:\n",
    "            m.printMesgAddStr(\" Filename          : \", c.getCyan(), target_file_cluster_lst[i])\n",
    "            m.printMesgAddStr(\"                   : \", c.getRed(), \"cannot be found check if file exist\")\n",
    "            #exit(c.get_RC_FAIL())\n",
    "        # [end-try-catch]\n",
    "    # [end-for-loop [i]]\n",
    "    return rc, target_file_cluster_filtered_lst\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "538e079e69a2a38c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plot_representation_matplotlib",
   "id": "c6e0c907b68857ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def plot_representation_matplotlib(c, m, dataframe_rep_lst, mach_name):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Create a combined DataFrame\n",
    "    #df_combined = pandas.concat([df_su2_adj_lumi, df_su2_fun_lumi, df_su3_fun_lumi])\n",
    "    df_combined = pandas.concat(dataframe_rep_lst)\n",
    "\n",
    "    # Get unique representations and their corresponding means\n",
    "    representations = df_combined[\"Representation\"].unique()\n",
    "    means = [df_combined[df_combined[\"Representation\"] == rep][\"CG Run Time (s)\"].mean() for rep in representations]\n",
    "\n",
    "    # Define bar positions\n",
    "    x = numpy.arange(len(representations))\n",
    "\n",
    "    # Create bar chart\n",
    "    fig, ax = matplotlib.pyplot.subplots(figsize=(8, 5))\n",
    "    bars = ax.bar(x, means, color=['blue', 'green', 'red'], alpha=0.7)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(representations, rotation=15)\n",
    "    ax.set_ylabel(\"Average CG Run Time (s) [\"+str(mach_name)+\"]\")\n",
    "    ax.set_title(\"Comparison of CG Run Time by Representation\")\n",
    "\n",
    "    # Add values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "        xytext=(0, 3),  # Offset label slightly\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "3bdbdd1d05d924bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plot_representation_seaborn",
   "id": "a8f06d2b109b924f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def plot_representation_seaborn(c, m, dataframe_rep_lst, mach_name, message):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Combine the filtered DataFrames\n",
    "    df_combined = pandas.concat(dataframe_rep_lst)\n",
    "\n",
    "    # Set the figure size\n",
    "    matplotlib.pyplot.figure(figsize=(8, 5))\n",
    "\n",
    "    # Create a Seaborn barplot\n",
    "    seaborn.barplot(data=df_combined, x=\"mpi_distribution\", y=\"CG Run Time (s)\" ) #, palette=\"coolwarm\", errorbar=None)\n",
    "\n",
    "    # Add labels and title\n",
    "    matplotlib.pyplot.xlabel(\"mpi_distribution\")\n",
    "    matplotlib.pyplot.ylabel(\"Average CG Run Time (s)\")\n",
    "    matplotlib.pyplot.title(\"[\"+str(mach_name)+\"] \"+str(message))\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    matplotlib.pyplot.xticks(rotation=15)\n",
    "\n",
    "    # Show the plot\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "934df7c579a9b823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plot_groupByBars_matplotlib",
   "id": "9b68fcdc48497841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def plot_groupByBars_matplotlib(c, m):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    species = (\"Adelie\", \"Chinstrap\", \"Gentoo\")\n",
    "    print(type(species))\n",
    "    print(species)\n",
    "    penguin_means = {\n",
    "        'Bill Depth': (18.35, 18.43, 14.98),\n",
    "        'Bill Length': (38.79, 48.83, 47.50),\n",
    "        'Flipper Length': (189.95, 195.82, 217.19),\n",
    "    }\n",
    "    print(type(penguin_means))\n",
    "\n",
    "    x = numpy.arange(len(species))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = matplotlib.pyplot.subplots(layout='constrained')\n",
    "\n",
    "    for attribute, measurement in penguin_means.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Length (mm)')\n",
    "    ax.set_title('Penguin attributes by species')\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, 250)\n",
    "\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "8a424e34498bfb5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plot_BenchRes_groupByBars_matplotlib",
   "id": "21a7ee2f8e484049"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                         df_mpi_distr,\n",
    "                                         df_su2_adj,\n",
    "                                         df_su2_fun,\n",
    "                                         df_su3_fun,\n",
    "                                         mach_name, message):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    species = tuple(df_mpi_distr)\n",
    "    #print(type(species))\n",
    "    #print(species)\n",
    "    grouped_data = {\n",
    "        'SU(2) Adj': df_su2_adj,\n",
    "        'SU(2) Fun': df_su2_fun,\n",
    "        'SU(3) Fun': df_su3_fun,\n",
    "    }\n",
    "    colors = ['magenta', 'blue', 'green'] #, 'red', 'black']\n",
    "    #print(type(penguin_means))\n",
    "\n",
    "    x = numpy.arange(len(species))  # the label locations\n",
    "    width = 0.3  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = matplotlib.pyplot.subplots(layout='constrained', figsize=(16, 10))\n",
    "\n",
    "    #for attribute, measurement in penguin_means.items():\n",
    "    for (attribute, measurement), color in zip(grouped_data.items(), colors):\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute, color=color)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_xlabel(c.getXaxis_label()) #'MPI distribution')\n",
    "    ax.set_ylabel(c.getYaxis_label()) #'CG Run Time (s)')\n",
    "\n",
    "    matplotlib.pyplot.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    ax.set_title(\"[\"+str(mach_name)+\"] \"+str(message))\n",
    "    ax.set_xticks(x + width, species)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    #ax.set_ylim(0, 250)\n",
    "\n",
    "    #arg_list=repr(tuple(fields)).replace(\"'\", \"\")[1:-1]\n",
    "    plot_dir = \"Plots\"\n",
    "    # Check whether the specified path exists or not\n",
    "    dir_exist = os.path.exists(plot_dir)\n",
    "    if not dir_exist:\n",
    "        m.printMesgAddStr(\"Directory does not exists  --->: \", c.getRed(), plot_dir)\n",
    "        # Create a new directory because it does not exist\n",
    "        m.printMesgAddStr(\"Directory is created       --->: \", c.getMagenta(), plot_dir)\n",
    "        try:\n",
    "            os.makedirs(plot_dir)\n",
    "        except IOError:\n",
    "            m.printMesgAddStr(\"Unable to create directory --->: \", c.getMagenta(), plot_dir)\n",
    "            plot_dir = \"./\"\n",
    "            m.printMesgAddStr(\"Output directory           --->: \", c.getMagenta(), plot_dir)\n",
    "    # [end-if]\n",
    "    png_out_filename = \"plot_GroupedBars_\" + \\\n",
    "                       str(message) + \"_\" + \\\n",
    "                       str(c.getYaxis_label()).replace(\" \",\"_\").replace(\"/\",\"\").replace(\"(\",\"\").replace(\")\",\"\") + \\\n",
    "                       \"_\" + \\\n",
    "                       str(mach_name) + \".png\"\n",
    "    output_file = os.path.join(plot_dir, png_out_filename)\n",
    "    # print(\"png_out_filename --->: \", png_out_filename)\n",
    "    m.printMesgAddStr(\"Grouped Bar plot saved to  --->: \", c.getMagenta(), output_file)\n",
    "    base_width = 300\n",
    "    matplotlib.pyplot.savefig(output_file, dpi=base_width)\n",
    "\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return rc\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "ec575761a283356c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### plot_BenchRes_SuccessFailure_pieChart_matplotlib",
   "id": "b6352cf5825b9bb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                     cluster_lst,\n",
    "                                                     cluster_filtered_lst,\n",
    "                                                     mach_name, message):\n",
    "    __func__= sys._getframe().f_code.co_name\n",
    "    rc = c.get_RC_SUCCESS()\n",
    "    m.printMesgStr(\"Getting target file list      :\", c.getGreen(), __func__)\n",
    "    # ----------------------------------------------------------------------\n",
    "    total_cluster = len(cluster_lst)\n",
    "    total_cluster_filtered = len(cluster_filtered_lst)\n",
    "    m.printMesgAddStr(\"len(cluster_lst[:])          --->: \", c.getYellow(), str(total_cluster))\n",
    "    m.printMesgAddStr(\"len(cluster_filtered_lst[:]) --->: \", c.getGreen(), str(total_cluster_filtered))\n",
    "    failed_lst = []\n",
    "    failed_lst.clear()\n",
    "    for i in range(len(cluster_lst[:])):\n",
    "        if cluster_lst[i] not in cluster_filtered_lst:\n",
    "            failed_lst.append(cluster_lst[i])\n",
    "        # [end-if]\n",
    "    # [end-loop[i]]\n",
    "    # Length of the failed runs\n",
    "    total_cluster_failed = len(failed_lst[:])\n",
    "    # Data to plot\n",
    "    labels = ['Total Runs', 'Total filtered Runs', 'Total failed Runs']\n",
    "    sizes = [total_cluster, total_cluster_filtered, total_cluster_failed ]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    explode = (0, 0, 0.1)  # Highlight Failed Runs\n",
    "\n",
    "    # Plot\n",
    "    matplotlib.pyplot.figure(figsize=(8, 8))\n",
    "    matplotlib.pyplot.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, explode=explode, shadow=True, startangle=140)\n",
    "\n",
    "    matplotlib.pyplot.title(\"[\"+str(mach_name)+\"] \"+str(message) + \" ---> Failed Runs\")\n",
    "\n",
    "    #arg_list=repr(tuple(fields)).replace(\"'\", \"\")[1:-1]\n",
    "    plot_dir = \"Plots\"\n",
    "    # Check whether the specified path exists or not\n",
    "    dir_exist = os.path.exists(plot_dir)\n",
    "    if not dir_exist:\n",
    "        m.printMesgAddStr(\"Directory does not exists  --->: \", c.getRed(), plot_dir)\n",
    "        # Create a new directory because it does not exist\n",
    "        m.printMesgAddStr(\"Directory is created       --->: \", c.getMagenta(), plot_dir)\n",
    "        try:\n",
    "            os.makedirs(plot_dir)\n",
    "        except IOError:\n",
    "            m.printMesgAddStr(\"Unable to create directory --->: \", c.getMagenta(), plot_dir)\n",
    "            plot_dir = \"./\"\n",
    "            m.printMesgAddStr(\"Output directory           --->: \", c.getMagenta(), plot_dir)\n",
    "    # [end-if]\n",
    "    # output to file\n",
    "    png_out_filename = \"plot_PieChart_\" + \\\n",
    "                       str(message) + \"_\" + \\\n",
    "                       str(\"FailedRuns\") + \\\n",
    "                       \"_\" + \\\n",
    "                       str(mach_name) + \".png\"\n",
    "    output_file = os.path.join(plot_dir, png_out_filename)\n",
    "    # print(\"png_out_filename --->: \", png_out_filename)\n",
    "    m.printMesgAddStr(\"Grouped Bar plot saved to  --->: \", c.getMagenta(), output_file)\n",
    "    base_width = 300\n",
    "    matplotlib.pyplot.savefig(output_file, dpi=base_width)\n",
    "\n",
    "    #matplotlib.pyplot.show()\n",
    "    # Summary\n",
    "    m.printMesgAddStr(\"Failed cluster lst           --->: \", c.getYellow(), failed_lst[:])\n",
    "    m.printMesgAddStr(\"len(cluster_failed_lst)      --->: \", c.getRed(), str(total_cluster_failed))\n",
    "    # Now plotting the pie chart.\n",
    "\n",
    "    return rc, failed_lst[:]\n",
    "# [end-function]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "5d8d7400d4690128",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lumi\n",
    "---"
   ],
   "id": "26352d43de99730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [BKeeper_run_gpu : small]",
   "id": "1943c8f7741307b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "machine_name_lumi = \"Lumi\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_lumi,'LatticeRuns')\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "269327d82d98614b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"BKeeper_run_gpu\"\n",
    "simulation_size=\"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "d356081392b5b746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_lst_lumi, target_file_dir_lumi = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "ee881dd986be3bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_cluster_lst_lumi = getTarget_file_cluster_lst(c, m, target_file_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "d35b470828562f39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                       : \", c.getGreen(), machine_name_lumi)\n",
    "m.printMesgAddStr(\"Simulation size                                   : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_file_cluster_lst_lumi[:]               --->: \", c.getYellow(), target_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"Length target_file_cluster_lst_lumi[:]        --->: \", c.getYellow(), len(target_file_cluster_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "837629d0c6e6df59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "rc, target_file_cluster_filtered_lst_lumi = filter_target_file_cluster_lst(c, m,\n",
    "                                                                           start_key_rep_lst[:],\n",
    "                                                                           target_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"len(target_file_cluster_filtered_lst_lumi[:]) --->: \", c.getYellow(), len(target_file_cluster_filtered_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "222d1dbbc56d5c15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, cluster_failed_lst_lumi = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                               target_file_cluster_lst_lumi[:],\n",
    "                                                                               target_file_cluster_filtered_lst_lumi[:],\n",
    "                                                                               machine_name_lumi, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "49bff686df4c787d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "#rc, dataFrame_BKeeper_small_lumi = read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_lst_lumi[:])\n",
    "rc, dataFrame_BKeeper_small_lumi = read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_filtered_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "769be543eea12ae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame BKeeper small Lumi-G                    : \", c.getGreen(), machine_name_lumi)\n",
    "dataFrame_BKeeper_small_lumi\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "11556e97bbe14fd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"Plots DataFrame BKeeper small Lumi-G              : \", c.getGreen(), machine_name_lumi)\n",
    "\n",
    "df_su2_adj_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi[\"Representation\"] == \"SU(2), adjoint\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su2_fun_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi[\"Representation\"] == \"SU(2), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su3_fun_lumi = dataFrame_BKeeper_small_lumi[dataFrame_BKeeper_small_lumi[\"Representation\"] == \"SU(3), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "aee8c0cc0b72e9c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"CG Run Time (s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_lumi_mpi_node001     = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_lumi_cgtimes_node001 = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_lumi_cgtimes_node001 = df_su2_fun_lumi[df_su2_fun_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_lumi_cgtimes_node001 = df_su3_fun_lumi[df_su3_fun_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_lumi_mpi_node001[x_label],\n",
    "                                          df_su2_adj_lumi_cgtimes_node001[y_label],\n",
    "                                          df_su2_fun_lumi_cgtimes_node001[y_label],\n",
    "                                          df_su3_fun_lumi_cgtimes_node001[y_label],\n",
    "                                          machine_name_lumi, msg)\n",
    "\n",
    "df_su2_adj_lumi_mpi_node002     = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_lumi_cgtimes_node002 = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_lumi_cgtimes_node002 = df_su2_fun_lumi[df_su2_fun_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_lumi_cgtimes_node002 = df_su3_fun_lumi[df_su3_fun_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_lumi_mpi_node002[x_label],\n",
    "                                          df_su2_adj_lumi_cgtimes_node002[y_label],\n",
    "                                          df_su2_fun_lumi_cgtimes_node002[y_label],\n",
    "                                          df_su3_fun_lumi_cgtimes_node002[y_label],\n",
    "                                          machine_name_lumi, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "c2c02622c71472c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# PLoting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"FlOp/S (GFlOp/s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_lumi_mpi_node001   = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_lumi_flops_node001 = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_lumi_flops_node001 = df_su2_fun_lumi[df_su2_fun_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_lumi_flops_node001 = df_su3_fun_lumi[df_su3_fun_lumi[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_lumi_mpi_node001[x_label],\n",
    "                                          df_su2_adj_lumi_flops_node001[y_label],\n",
    "                                          df_su2_fun_lumi_flops_node001[y_label],\n",
    "                                          df_su3_fun_lumi_flops_node001[y_label],\n",
    "                                          machine_name_lumi, msg)\n",
    "\n",
    "df_su2_adj_lumi_mpi_node002   = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_lumi_flops_node002 = df_su2_adj_lumi[df_su2_adj_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_lumi_flops_node002 = df_su2_fun_lumi[df_su2_fun_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_lumi_flops_node002 = df_su3_fun_lumi[df_su3_fun_lumi[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_lumi_mpi_node002[x_label],\n",
    "                                          df_su2_adj_lumi_flops_node002[y_label],\n",
    "                                          df_su2_fun_lumi_flops_node002[y_label],\n",
    "                                          df_su3_fun_lumi_flops_node002[y_label],\n",
    "                                          machine_name_lumi, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "2ade2f0934d721c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : small]",
   "id": "8d2a25533066f6e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_weak_cpu\"\n",
    "simulation_size=\"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "b3c9d33ebb91e198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepency, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "rc, target_Sombrero_weak_small_file_lst_lumi, target_Sombrero_weak_small_file_dir_lumi = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "2be1f387716939c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_weak_small_file_cluster_lst_lumi = getTarget_file_cluster_lst(c, m, target_Sombrero_weak_small_file_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "6b6208551670687f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                    : \", c.getGreen(), machine_name_lumi)\n",
    "m.printMesgAddStr(\"Simulation size                                                : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_weak_small_file_cluster_lst_lumi[:]        --->: \", c.getYellow(), target_Sombrero_weak_small_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_weak_small_file_cluster_lst_lumi[:] --->: \", c.getYellow(), len(target_Sombrero_weak_small_file_cluster_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "83ba84cad1cb0141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_weak_small_file_cluster_filtered_lst_lumi = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                               start_key_sombrero_rep_lst[:],\n",
    "                                                                                               target_Sombrero_weak_small_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_weak_small_file_cluster_filtered_lst_lumi[:]) --->: \", c.getYellow(), len(target_Sombrero_weak_small_file_cluster_filtered_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "6d3e91663e3ad685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_weak_small_file_cluster_failed_lst_lumi = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                        target_Sombrero_weak_small_file_cluster_lst_lumi[:],\n",
    "                                                                                                        target_Sombrero_weak_small_file_cluster_filtered_lst_lumi[:],\n",
    "                                                                                                        machine_name_lumi, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "b0916b510242d59f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size=\"small\"\n",
    "rc, dataFrame_Sombrero_weak_small_lumi = read_Sombrero_file_out(c, m,\n",
    "                                                                batch_action, simulation_size,\n",
    "                                                                target_Sombrero_weak_small_file_cluster_lst_lumi)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "bd02b4f1564f5af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak small Lumi-C              : \", c.getGreen(), machine_name_lumi)\n",
    "dataFrame_Sombrero_weak_small_lumi\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "d2335d76e8020175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : large]",
   "id": "ae77dd8a22afadaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_weak_cpu\"\n",
    "simulation_size=\"large\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "eacf437df7f9e7e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepency, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "rc, target_Sombrero_weak_large_file_lst_lumi, target_Sombrero_weak_large_file_dir_lumi = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "43daa574660dee2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_weak_large_file_cluster_lst_lumi = getTarget_file_cluster_lst(c, m, target_Sombrero_weak_large_file_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "fe59cfc576834a11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                    : \", c.getGreen(), machine_name_lumi)\n",
    "m.printMesgAddStr(\"Simulation size                                                : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_weak_large_file_cluster_lst_lumi[:]        --->: \", c.getYellow(), target_Sombrero_weak_large_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_weak_large_file_cluster_lst_lumi[:] --->: \", c.getYellow(), len(target_Sombrero_weak_large_file_cluster_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "1920648e55eb8fa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_weak_large_file_cluster_filtered_lst_lumi = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                               start_key_sombrero_rep_lst[:],\n",
    "                                                                                               target_Sombrero_weak_large_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_weak_large_file_cluster_filtered_lst_lumi[:]) --->: \", c.getYellow(), len(target_Sombrero_weak_large_file_cluster_filtered_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "8f5288dcd2ef1de8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_weak_large_file_cluster_failed_lst_lumi = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                        target_Sombrero_weak_large_file_cluster_lst_lumi[:],\n",
    "                                                                                                        target_Sombrero_weak_large_file_cluster_filtered_lst_lumi[:],\n",
    "                                                                                                        machine_name_lumi, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "3d370cdc3d8df4ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size=\"large\"\n",
    "rc, dataFrame_Sombrero_weak_large_lumi = read_Sombrero_file_out(c, m,\n",
    "                                                                batch_action, simulation_size,\n",
    "                                                                target_Sombrero_weak_large_file_cluster_lst_lumi)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "3577e46dc60b5ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak large Lumi-C              : \", c.getGreen(), machine_name_lumi)\n",
    "dataFrame_Sombrero_weak_large_lumi\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "4fef5eff6c24f5b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : small]",
   "id": "d1d17fc06ad99f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_strg_cpu\"\n",
    "simulation_size=\"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "3e4ae7f48a07af85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and\n",
    "# TODO: batch script discrepancy, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "rc, target_Sombrero_strong_small_file_lst_lumi, target_Sombrero_strong_small_file_dir_lumi = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "aeb784311b5f5069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_strong_small_file_cluster_lst_lumi = getTarget_file_cluster_lst(c, m, target_Sombrero_strong_small_file_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "6b5427fee0880812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                      : \", c.getGreen(), machine_name_lumi)\n",
    "m.printMesgAddStr(\"Simulation size                                                  : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_strong_small_file_cluster_lst_lumi[:]        --->: \", c.getYellow(), target_Sombrero_strong_small_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_strong_small_file_cluster_lst_lumi[:] --->: \", c.getYellow(), len(target_Sombrero_strong_small_file_cluster_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "a30bd861fbcd9b94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_strong_small_file_cluster_filtered_lst_lumi = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                               start_key_sombrero_rep_lst[:],\n",
    "                                                                                               target_Sombrero_strong_small_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_strong_small_file_cluster_filtered_lst_lumi[:]) --->: \", c.getYellow(), len(target_Sombrero_strong_small_file_cluster_filtered_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "df2acf79e8b7f96e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_strong_small_file_cluster_failed_lst_lumi = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                        target_Sombrero_strong_small_file_cluster_lst_lumi[:],\n",
    "                                                                                                        target_Sombrero_strong_small_file_cluster_filtered_lst_lumi[:],\n",
    "                                                                                                        machine_name_lumi, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "6575f25e5a63a6f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size=\"small\"\n",
    "rc, dataFrame_Sombrero_strong_small_lumi = read_Sombrero_file_out(c, m,\n",
    "                                                                batch_action, simulation_size,\n",
    "                                                                target_Sombrero_strong_small_file_cluster_lst_lumi)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "dc3d8da76eb722de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong small Lumi-C            : \", c.getGreen(), machine_name_lumi)\n",
    "dataFrame_Sombrero_strong_small_lumi\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "ca181285a6308d4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : large]",
   "id": "59bc8f2e7c2f782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_strg_cpu\"\n",
    "simulation_size=\"large\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "a35066e36a9a5eca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepency, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "rc, target_Sombrero_strong_large_file_lst_lumi, target_Sombrero_strong_large_file_dir_lumi = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "2c8cb547855750fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_strong_large_file_cluster_lst_lumi = getTarget_file_cluster_lst(c, m, target_Sombrero_strong_large_file_lst_lumi[:])\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "e210fc5597e672c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                      : \", c.getGreen(), machine_name_lumi)\n",
    "m.printMesgAddStr(\"Simulation size                                                  : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_strong_large_file_cluster_lst_lumi[:]        --->: \", c.getYellow(), target_Sombrero_strong_large_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_strong_large_file_cluster_lst_lumi[:] --->: \", c.getYellow(), len(target_Sombrero_strong_large_file_cluster_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "444daacc56fbba94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_strong_large_file_cluster_filtered_lst_lumi = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                                 start_key_sombrero_rep_lst[:],\n",
    "                                                                                                 target_Sombrero_strong_large_file_cluster_lst_lumi[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_strong_small_file_cluster_filtered_lst_lumi[:]) --->: \", c.getYellow(), len(target_Sombrero_strong_large_file_cluster_filtered_lst_lumi[:]))\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "b71d21c94a787ba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_strong_large_file_cluster_failed_lst_lumi = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                          target_Sombrero_strong_large_file_cluster_lst_lumi[:],\n",
    "                                                                                                          target_Sombrero_strong_large_file_cluster_filtered_lst_lumi[:],\n",
    "                                                                                                          machine_name_lumi, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "4892dfd1cd2f323f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size=\"large\"\n",
    "rc, dataFrame_Sombrero_strong_large_lumi = read_Sombrero_file_out(c, m,\n",
    "                                                                  batch_action, simulation_size,\n",
    "                                                                  target_Sombrero_strong_large_file_cluster_lst_lumi)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "2c977fc4cd40283e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong large small Lumi-C      : \", c.getGreen(), machine_name_lumi)\n",
    "dataFrame_Sombrero_strong_large_lumi\n",
    "# ----------------------------------------------------------------------------\n"
   ],
   "id": "8d2a6d5395863929",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vega\n",
    "---"
   ],
   "id": "5255f7539620b891"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [BKeeper_run_gpu : small]",
   "id": "6baf30c4081ee933"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_vega = \"Vega\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_vega,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "cb158d60922eb51c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reinitialising the paths and object content.\n",
    "batch_action = \"BKeeper_run_gpu\"\n",
    "simulation_size=\"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "f43b1c84d820137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_lst_vega, target_file_dir_vega = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "345ed4054122875d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_cluster_lst_vega = getTarget_file_cluster_lst(c, m, target_file_lst_vega[:])\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "301a84c8fe4a047d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                       : \", c.getGreen(), machine_name_vega)\n",
    "m.printMesgAddStr(\"Simulation size                                   : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_file_cluster_lst_vega[:]               --->: \", c.getYellow(), target_file_cluster_lst_vega[:])\n",
    "m.printMesgAddStr(\"Length target_file_cluster_lst_vega[:]        --->: \", c.getYellow(), len(target_file_cluster_lst_vega[:]))\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "b401a4ca382732f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "rc, target_file_cluster_filtered_lst_vega = filter_target_file_cluster_lst(c, m,\n",
    "                                                                           start_key_rep_lst[:],\n",
    "                                                                           target_file_cluster_lst_vega[:])\n",
    "\n",
    "m.printMesgAddStr(\"len(target_file_cluster_filtered_lst_vega[:]) --->: \", c.getYellow(), len(target_file_cluster_filtered_lst_vega[:]))\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "b8fa8d2fb7914545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, cluster_failed_lst_vega = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                          target_file_cluster_lst_vega[:],\n",
    "                                                                          target_file_cluster_filtered_lst_vega[:],\n",
    "                                                                          machine_name_vega, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "89bfcfd044ee2be8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "rc, dataFrame_BKeeper_small_vega = read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_filtered_lst_vega[:])\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "1eb9ceadaa2ce03e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame BKeeper small Vega-GPU                  : \", c.getGreen(), machine_name_vega)\n",
    "dataFrame_BKeeper_small_vega\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "c7b32ded4b8c11e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"Plots DataFrame BKeeper small Vega-G              : \", c.getGreen(), machine_name_vega)\n",
    "\n",
    "df_su2_adj_vega = dataFrame_BKeeper_small_vega[dataFrame_BKeeper_small_vega[\"Representation\"] == \"SU(2), adjoint\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su2_fun_vega = dataFrame_BKeeper_small_vega[dataFrame_BKeeper_small_vega[\"Representation\"] == \"SU(2), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su3_fun_vega = dataFrame_BKeeper_small_vega[dataFrame_BKeeper_small_vega[\"Representation\"] == \"SU(3), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "bcfc969e7f881dac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"CG Run Time (s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_vega_mpi_node001     = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_vega_cgtimes_node001 = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_vega_cgtimes_node001 = df_su2_fun_vega[df_su2_fun_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_vega_cgtimes_node001 = df_su3_fun_vega[df_su3_fun_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_vega_mpi_node001[x_label],\n",
    "                                          df_su2_adj_vega_cgtimes_node001[y_label],\n",
    "                                          df_su2_fun_vega_cgtimes_node001[y_label],\n",
    "                                          df_su3_fun_vega_cgtimes_node001[y_label],\n",
    "                                          machine_name_vega, msg)\n",
    "\n",
    "df_su2_adj_vega_mpi_node002     = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_vega_cgtimes_node002 = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_vega_cgtimes_node002 = df_su2_fun_vega[df_su2_fun_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_vega_cgtimes_node002 = df_su3_fun_vega[df_su3_fun_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_vega_mpi_node002[x_label],\n",
    "                                          df_su2_adj_vega_cgtimes_node002[y_label],\n",
    "                                          df_su2_fun_vega_cgtimes_node002[y_label],\n",
    "                                          df_su3_fun_vega_cgtimes_node002[y_label],\n",
    "                                          machine_name_vega, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "915b4d14c6fb2ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"FlOp/S (GFlOp/s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_vega_mpi_node001     = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_vega_flops_node001 = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_vega_flops_node001 = df_su2_fun_vega[df_su2_fun_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_vega_flops_node001 = df_su3_fun_vega[df_su3_fun_vega[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_vega_mpi_node001[x_label],\n",
    "                                          df_su2_adj_vega_flops_node001[y_label],\n",
    "                                          df_su2_fun_vega_flops_node001[y_label],\n",
    "                                          df_su3_fun_vega_flops_node001[y_label],\n",
    "                                          machine_name_vega, msg)\n",
    "\n",
    "df_su2_adj_vega_mpi_node002     = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_vega_flops_node002 = df_su2_adj_vega[df_su2_adj_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_vega_flops_node002 = df_su2_fun_vega[df_su2_fun_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_vega_flops_node002 = df_su3_fun_vega[df_su3_fun_vega[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_vega_mpi_node002[x_label],\n",
    "                                          df_su2_adj_vega_flops_node002[y_label],\n",
    "                                          df_su2_fun_vega_flops_node002[y_label],\n",
    "                                          df_su3_fun_vega_flops_node002[y_label],\n",
    "                                          machine_name_vega, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "9f60975100a7bd86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "6d62e4d045b1212b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : small]",
   "id": "e03d0de166b618ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_vega = \"Vega\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns', 'Clusters', machine_name_vega, 'LatticeRuns')\n",
    "# --------------------------------------------------------------------------\n",
    "target_batch_action = \"Sombrero_weak_cpu\"\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size = \"small\"\n",
    "# --------------------------------------------------------------------------\n",
    "rc, dataFrame_Sombrero_weak_small_vega = getDataFrame_from_Sombrero_Runs(c,m,\n",
    "                                                                         DATA_PATH, machine_name_vega,\n",
    "                                                                         target_batch_action,\n",
    "                                                                         batch_action,\n",
    "                                                                         simulation_size,\n",
    "                                                                         start_key_sombrero_rep_lst)\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak small Vega-cpu            : \", c.getGreen(), machine_name_vega)\n",
    "dataFrame_Sombrero_weak_small_vega\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "88ea13db1625633a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : large]",
   "id": "8a32925ff95fb8c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_vega = \"Vega\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns', 'Clusters', machine_name_vega, 'LatticeRuns')\n",
    "# --------------------------------------------------------------------------\n",
    "target_batch_action = \"Sombrero_weak_cpu\"\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size = \"large\"\n",
    "# --------------------------------------------------------------------------\n",
    "rc, dataFrame_Sombrero_weak_large_vega = getDataFrame_from_Sombrero_Runs(c,m,\n",
    "                                                                         DATA_PATH, machine_name_vega,\n",
    "                                                                         target_batch_action,\n",
    "                                                                         batch_action,\n",
    "                                                                         simulation_size,\n",
    "                                                                         start_key_sombrero_rep_lst)\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak small Vega-cpu            : \", c.getGreen(), machine_name_vega)\n",
    "dataFrame_Sombrero_weak_large_vega\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "819e54566dd80675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : small]",
   "id": "7fb33de1bdea33a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_vega = \"Vega\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns', 'Clusters', machine_name_vega, 'LatticeRuns')\n",
    "# --------------------------------------------------------------------------\n",
    "target_batch_action = \"Sombrero_strg_cpu\"\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size = \"small\"\n",
    "# --------------------------------------------------------------------------\n",
    "rc, dataFrame_Sombrero_strong_small_vega = getDataFrame_from_Sombrero_Runs(c,m,\n",
    "                                                                           DATA_PATH, machine_name_vega,\n",
    "                                                                           target_batch_action,\n",
    "                                                                           batch_action,\n",
    "                                                                           simulation_size,\n",
    "                                                                           start_key_sombrero_rep_lst)\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong small Vega-cpu          : \", c.getGreen(), machine_name_vega)\n",
    "dataFrame_Sombrero_strong_small_vega\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "268dc8972af8ed8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : large]",
   "id": "4427f65d308c0172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_vega = \"Vega\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns', 'Clusters', machine_name_vega, 'LatticeRuns')\n",
    "# --------------------------------------------------------------------------\n",
    "target_batch_action = \"Sombrero_strg_cpu\"\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size = \"large\"\n",
    "# --------------------------------------------------------------------------\n",
    "rc, dataFrame_Sombrero_strong_large_vega = getDataFrame_from_Sombrero_Runs(c,m,\n",
    "                                                                           DATA_PATH, machine_name_vega,\n",
    "                                                                           target_batch_action,\n",
    "                                                                           batch_action,\n",
    "                                                                           simulation_size,\n",
    "                                                                           start_key_sombrero_rep_lst)\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong large Vega-cpu          : \", c.getGreen(), machine_name_vega)\n",
    "dataFrame_Sombrero_strong_large_vega\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "eebdb6abae0f775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "73600cebce57bba6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Leonardo\n",
    "---\n",
    "### [BKeeper_run_gpu : small]"
   ],
   "id": "726568a84456c431"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_leonardo = \"Leonardo\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_leonardo,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "4440196c8cd3288b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reinitialising the paths and object content.\n",
    "batch_action = \"BKeeper_run_gpu\"\n",
    "simulation_size=\"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "f81103bf0133cf27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_lst_leonardo, target_file_dir_leonardo = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "557762140af3fc96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_file_cluster_lst_leonardo = getTarget_file_cluster_lst(c, m, target_file_lst_leonardo[:])\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "bbfed3dcdee3a38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                    : \", c.getGreen(), machine_name_leonardo)\n",
    "m.printMesgAddStr(\"Simulation size                                : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_file_cluster_lst_leonardo[:]        --->: \", c.getYellow(), target_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"Length target_file_cluster_lst_leonardo[:] --->: \", c.getYellow(), len(target_file_cluster_lst_leonardo[:]))\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "fbf7288450f24c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "rc, target_file_cluster_filtered_lst_leonardo = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                start_key_rep_lst[:],\n",
    "                                                                                target_file_cluster_lst_leonardo[:])\n",
    "\n",
    "m.printMesgAddStr(\"len(target_file_cluster_filtered_lst_leonardo[:]) --->: \", c.getYellow(), len(target_file_cluster_filtered_lst_leonardo[:]))\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "923f74ac943d2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, cluster_failed_lst_leonardo = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                          target_file_cluster_lst_leonardo[:],\n",
    "                                                                          target_file_cluster_filtered_lst_leonardo[:],\n",
    "                                                                          machine_name_leonardo, msg)\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "5af0fc3f46380124",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "rc, dataFrame_BKeeper_small_leonardo = read_BKeeper_file_out(c, m, batch_action, simulation_size, target_file_cluster_filtered_lst_leonardo[:])\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "3e8598f60d767ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame BKeeper small Leonardo-Booster          : \", c.getGreen(), machine_name_leonardo)\n",
    "dataFrame_BKeeper_small_leonardo\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "c4bb8c97e664960e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"Plots DataFrame BKeeper small Leonardo-Booster    : \", c.getGreen(), machine_name_leonardo)\n",
    "\n",
    "df_su2_adj_leonardo = dataFrame_BKeeper_small_leonardo[dataFrame_BKeeper_small_leonardo[\"Representation\"] == \"SU(2), adjoint\"][[\"Representation\", \"CG Run Time (s)\", \"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su2_fun_leonardo = dataFrame_BKeeper_small_leonardo[dataFrame_BKeeper_small_leonardo[\"Representation\"] == \"SU(2), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "df_su3_fun_leonardo = dataFrame_BKeeper_small_leonardo[dataFrame_BKeeper_small_leonardo[\"Representation\"] == \"SU(3), fundamental\"][[\"Representation\", \"CG Run Time (s)\",\"mpi_distribution\",\"nodes\", \"FlOp/S (GFlOp/s)\"]]\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "6c2678f836f08936",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"CG Run Time (s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_leonardo_mpi_node001     = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_leonardo_cgtimes_node001 = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_leonardo_cgtimes_node001 = df_su2_fun_leonardo[df_su2_fun_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_leonardo_cgtimes_node001 = df_su3_fun_leonardo[df_su3_fun_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_leonardo_mpi_node001[x_label],\n",
    "                                          df_su2_adj_leonardo_cgtimes_node001[y_label],\n",
    "                                          df_su2_fun_leonardo_cgtimes_node001[y_label],\n",
    "                                          df_su3_fun_leonardo_cgtimes_node001[y_label],\n",
    "                                          machine_name_leonardo, msg)\n",
    "\n",
    "df_su2_adj_leonardo_mpi_node002     = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_leonardo_cgtimes_node002 = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_leonardo_cgtimes_node002 = df_su2_fun_leonardo[df_su2_fun_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_leonardo_cgtimes_node002 = df_su3_fun_leonardo[df_su3_fun_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_leonardo_mpi_node002[x_label],\n",
    "                                          df_su2_adj_leonardo_cgtimes_node002[y_label],\n",
    "                                          df_su2_fun_leonardo_cgtimes_node002[y_label],\n",
    "                                          df_su3_fun_leonardo_cgtimes_node002[y_label],\n",
    "                                          machine_name_leonardo, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "42363e48fe0dc9fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "x_label = \"mpi_distribution\"\n",
    "y_label = \"FlOp/S (GFlOp/s)\"\n",
    "\n",
    "c.setXaxis_label(x_label)\n",
    "c.setYaxis_label(y_label)\n",
    "\n",
    "df_su2_adj_leonardo_mpi_node001   = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"001\"][[x_label]]\n",
    "df_su2_adj_leonardo_flops_node001 = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su2_fun_leonardo_flops_node001 = df_su2_fun_leonardo[df_su2_fun_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "df_su3_fun_leonardo_flops_node001 = df_su3_fun_leonardo[df_su3_fun_leonardo[\"nodes\"] == \"001\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node001\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_leonardo_mpi_node001[x_label],\n",
    "                                          df_su2_adj_leonardo_flops_node001[y_label],\n",
    "                                          df_su2_fun_leonardo_flops_node001[y_label],\n",
    "                                          df_su3_fun_leonardo_flops_node001[y_label],\n",
    "                                          machine_name_leonardo, msg)\n",
    "\n",
    "df_su2_adj_leonardo_mpi_node002   = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"002\"][[x_label]]\n",
    "df_su2_adj_leonardo_flops_node002 = df_su2_adj_leonardo[df_su2_adj_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su2_fun_leonardo_flops_node002 = df_su2_fun_leonardo[df_su2_fun_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "df_su3_fun_leonardo_flops_node002 = df_su3_fun_leonardo[df_su3_fun_leonardo[\"nodes\"] == \"002\"][[y_label]]\n",
    "\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"node002\"\n",
    "\n",
    "rc = plot_BenchRes_groupByBars_matplotlib(c, m,\n",
    "                                          df_su2_adj_leonardo_mpi_node002[x_label],\n",
    "                                          df_su2_adj_leonardo_flops_node002[y_label],\n",
    "                                          df_su2_fun_leonardo_flops_node002[y_label],\n",
    "                                          df_su3_fun_leonardo_flops_node002[y_label],\n",
    "                                          machine_name_leonardo, msg)\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "f51015d34bce4338",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "bc2d08d3554a2576"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : small]",
   "id": "3605d9e8d363c50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_leonardo = \"Leonardo\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_leonardo,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_weak_cpu\"\n",
    "simulation_size = \"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepancy, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "rc, target_Sombrero_weak_small_file_lst_leonardo, target_Sombrero_weak_small_file_dir_leonardo = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_weak_small_file_cluster_lst_leonardo = getTarget_file_cluster_lst(c, m, target_Sombrero_weak_small_file_lst_leonardo[:])\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                        : \", c.getGreen(), machine_name_leonardo)\n",
    "m.printMesgAddStr(\"Simulation size                                                    : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_weak_small_file_cluster_lst_leonardo[:]        --->: \", c.getYellow(), target_Sombrero_weak_small_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_weak_small_file_cluster_lst_leonardo[:] --->: \", c.getYellow(), len(target_Sombrero_weak_small_file_cluster_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_weak_small_file_cluster_filtered_lst_leonardo = filter_target_file_cluster_lst(c, m, start_key_sombrero_rep_lst[:],\n",
    "                                                                                               target_Sombrero_weak_small_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_weak_small_file_cluster_filtered_lst_leonardo[:]) --->: \", c.getYellow(), len(target_Sombrero_weak_small_file_cluster_filtered_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_weak_small_file_cluster_failed_lst_leonardo = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                        target_Sombrero_weak_small_file_cluster_lst_leonardo[:],\n",
    "                                                                                                        target_Sombrero_weak_small_file_cluster_filtered_lst_leonardo[:],\n",
    "                                                                                                        machine_name_leonardo,\n",
    "                                                                                                        msg)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size = \"small\"\n",
    "rc, dataFrame_Sombrero_weak_small_leonardo = read_Sombrero_file_out(c, m,\n",
    "                                                                batch_action, simulation_size,\n",
    "                                                                target_Sombrero_weak_small_file_cluster_lst_leonardo)\n",
    "# --------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak small Leonardo-DCGP       : \", c.getGreen(), machine_name_leonardo)\n",
    "dataFrame_Sombrero_weak_small_leonardo\n",
    "# ----------------------------------------------------------------------------\n"
   ],
   "id": "e2b20acd4e19700e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_weak : large]",
   "id": "44f1b8ee58a0e894"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_leonardo = \"Leonardo\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_leonardo,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_weak_cpu\"\n",
    "simulation_size = \"large\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepency, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "rc, target_Sombrero_weak_large_file_lst_leonardo, target_Sombrero_weak_large_file_dir_leonardo = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_weak_large_file_cluster_lst_leonardo = getTarget_file_cluster_lst(c, m, target_Sombrero_weak_large_file_lst_leonardo[:])\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                        : \", c.getGreen(), machine_name_leonardo)\n",
    "m.printMesgAddStr(\"Simulation size                                                    : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_weak_large_file_cluster_lst_leonardo[:]        --->: \", c.getYellow(), target_Sombrero_weak_large_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_weak_large_file_cluster_lst_leonardo[:] --->: \", c.getYellow(), len(target_Sombrero_weak_large_file_cluster_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_weak_large_file_cluster_filtered_lst_leonardo = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                                   start_key_sombrero_rep_lst[:],\n",
    "                                                                                                   target_Sombrero_weak_large_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_weak_large_file_cluster_filtered_lst_leonardo[:]) --->: \", c.getYellow(), len(target_Sombrero_weak_large_file_cluster_filtered_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_weak_large_file_cluster_failed_lst_leonardo = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                        target_Sombrero_weak_large_file_cluster_lst_leonardo[:],\n",
    "                                                                                                        target_Sombrero_weak_large_file_cluster_filtered_lst_leonardo[:],\n",
    "                                                                                                        machine_name_leonardo,\n",
    "                                                                                                        msg)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_weak\"\n",
    "simulation_size = \"large\"\n",
    "rc, dataFrame_Sombrero_weak_large_leonardo = read_Sombrero_file_out(c, m,\n",
    "                                                                batch_action, simulation_size,\n",
    "                                                                target_Sombrero_weak_large_file_cluster_lst_leonardo)\n",
    "# --------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Weak large Leonardo-DCGP       : \", c.getGreen(), machine_name_leonardo)\n",
    "dataFrame_Sombrero_weak_large_leonardo\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "2a0d425602b5f570",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : small]",
   "id": "235c62e445635148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_leonardo = \"Leonardo\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_leonardo,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_strg_cpu\"\n",
    "simulation_size = \"small\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and\n",
    "# TODO: batch script discrepancy, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "rc, target_Sombrero_strong_small_file_lst_leonardo, target_Sombrero_strong_small_file_dir_leonardo = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_strong_small_file_cluster_lst_leonardo  = getTarget_file_cluster_lst(c, m, target_Sombrero_strong_small_file_lst_leonardo [:])\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(   \"Data extraction cluster out                                          : \", c.getGreen(), machine_name_leonardo)\n",
    "m.printMesgAddStr(\"Simulation size                                                      : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_strong_small_file_cluster_lst_leonardo[:]        --->: \", c.getYellow(), target_Sombrero_strong_small_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_strong_small_file_cluster_lst_leonardo[:] --->: \", c.getYellow(), len(target_Sombrero_strong_small_file_cluster_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_strong_small_file_cluster_filtered_lst_leonardo = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                                 start_key_sombrero_rep_lst[:],\n",
    "                                                                                                 target_Sombrero_strong_small_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_strong_small_file_cluster_filtered_lst_leonardo[:]) --->: \", c.getYellow(), len(target_Sombrero_strong_small_file_cluster_filtered_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_strong_small_file_cluster_failed_lst_leonardo = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                              target_Sombrero_strong_small_file_cluster_lst_leonardo[:],\n",
    "                                                                                                              target_Sombrero_strong_small_file_cluster_filtered_lst_leonardo[:],\n",
    "                                                                                                              machine_name_lumi,\n",
    "                                                                                                              msg)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size = \"small\"\n",
    "rc, dataFrame_Sombrero_strong_small_leonardo = read_Sombrero_file_out(c, m,\n",
    "                                                                      batch_action, simulation_size,\n",
    "                                                                      target_Sombrero_strong_small_file_cluster_lst_leonardo)\n",
    "# --------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong small Leonardo-DCGP     : \", c.getGreen(), machine_name_leonardo)\n",
    "dataFrame_Sombrero_strong_small_leonardo\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "f099b9fdad561f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### [Sombrero_strong : large]",
   "id": "e536cc2f74533d69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "machine_name_leonardo = \"Leonardo\"\n",
    "DATA_PATH         = os.path.join('E:','LatticeRuns','Clusters',machine_name_leonardo,'LatticeRuns')\n",
    "# --------------------------------------------------------------------------# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "batch_action = \"Sombrero_strg_cpu\"\n",
    "simulation_size = \"large\"\n",
    "rc = Reinitialising_Paths_and_object_content(c, m, DATA_PATH, batch_action, simulation_size)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "# TODO: redefinition neccessary to to act on the target file name _cpu and batch script discrepency, batch action will need to be passed in. in the cluster method.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "rc, target_Sombrero_strong_large_file_lst_leonardo, target_Sombrero_strong_large_file_dir_leonardo = getTarget_file_lst(c, m, c.getTargetdir())\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Getting content in the target file\n",
    "rc, target_Sombrero_strong_large_file_cluster_lst_leonardo = getTarget_file_cluster_lst(c, m, target_Sombrero_strong_large_file_lst_leonardo[:])\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# [Data-Extraction]\n",
    "# --------------------------------------------------------------------------\n",
    "m.printMesgStr(\"Data extraction cluster out                                             : \", c.getGreen(), machine_name_leonardo)\n",
    "m.printMesgAddStr(\"Simulation size                                                      : \", c.getRed(), simulation_size)\n",
    "m.printMesgAddStr(\"target_Sombrero_strong_large_file_cluster_lst_leonardo[:]        --->: \", c.getYellow(), target_Sombrero_strong_large_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"Length target_Sombrero_strong_large_file_cluster_lst_leonardo[:] --->: \", c.getYellow(), len(target_Sombrero_strong_large_file_cluster_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "rc, target_Sombrero_strong_large_file_cluster_filtered_lst_leonardo = filter_target_file_cluster_lst(c, m,\n",
    "                                                                                                     start_key_sombrero_rep_lst[:],\n",
    "                                                                                                     target_Sombrero_strong_large_file_cluster_lst_leonardo[:])\n",
    "m.printMesgAddStr(\"len(target_Sombrero_strong_small_file_cluster_filtered_lst_leonardo[:]) --->: \", c.getYellow(), len(target_Sombrero_strong_large_file_cluster_filtered_lst_leonardo[:]))\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done.\n",
    "msg = batch_action + \"_\" + simulation_size + \"_\" + \"all nodes\"\n",
    "rc, Sombrero_strong_large_file_cluster_failed_lst_leonardo = plot_BenchRes_SuccessFailure_pieChart_matplotlib(c, m,\n",
    "                                                                                                              target_Sombrero_strong_large_file_cluster_lst_leonardo[:],\n",
    "                                                                                                              target_Sombrero_strong_large_file_cluster_filtered_lst_leonardo[:],\n",
    "                                                                                                              machine_name_lumi,\n",
    "                                                                                                              msg)\n",
    "# ----------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "# TODO: return to this one once the read_Sombrero_file_out method is done and replace with the filtered list\n",
    "# TODO: instead. For now we are going to use the full unfiltered list.\n",
    "batch_action = \"Sombrero_strong\"\n",
    "simulation_size = \"large\"\n",
    "rc, dataFrame_Sombrero_strong_large_leonardo = read_Sombrero_file_out(c, m,\n",
    "                                                                  batch_action, simulation_size,\n",
    "                                                                  target_Sombrero_strong_large_file_cluster_lst_leonardo)\n",
    "# --------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------\n",
    "# Reading in the inout file\n",
    "m.printMesgStr(\"DataFrame Sombrero Strong large small Leonardo-DCGP    : \", c.getGreen(), machine_name_leonardo)\n",
    "dataFrame_Sombrero_strong_large_leonardo\n",
    "# ----------------------------------------------------------------------------"
   ],
   "id": "fc1d5f1d9b886a82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "----"
   ],
   "id": "15087c5afc1b008d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combined plots\n",
    "---\n",
    "### [BKeeper_run_gpu : small]"
   ],
   "id": "b5b8298c7af6d680"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Plotting data\n",
    "dataframe_representation_lst_combined = [df_su2_adj_lumi   , df_su2_fun_lumi    , df_su3_fun_lumi    ,\n",
    "                                        df_su2_adj_vega    , df_su2_fun_vega    , df_su3_fun_vega    ,\n",
    "                                        df_su2_adj_leonardo, df_su2_fun_leonardo, df_su3_fun_leonardo]\n",
    "\n",
    "rc = plot_representation_matplotlib(c, m, dataframe_representation_lst_combined, str(machine_name_lumi+\",\"+machine_name_vega+\",\"+machine_name_leonardo))\n",
    "# --------------------------------------------------------------------------"
   ],
   "id": "25fdb4bd4ac413d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
